{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "\n",
    "# from gensim.models.doc2vec import Doc2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "config_path = '../config/20news.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ef74f4587a74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mUSE_MODULE_URL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m \u001b[1;31m# updated the url to match tf2 requirements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mUSE_EMBED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUSE_MODULE_URL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m       \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m   \"\"\"\n\u001b[1;32m--> 528\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[0;32m    550\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[0;32m    551\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                           export_dir)\n\u001b[0m\u001b[0;32m    553\u001b[0m       \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[0;32m    112\u001b[0m     self._concrete_functions = (\n\u001b[0;32m    113\u001b[0m         function_deserialization.load_function_def_library(\n\u001b[1;32m--> 114\u001b[1;33m             meta_graph.graph_def.library))\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcrete_function\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[1;34m(library, load_shared_name_suffix)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;31m# function before and passed in explicitly (due to the topologic sort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;31m# import).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m     \u001b[0mfunc_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction_def_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_def_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m     \u001b[0m_restore_gradient_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenamed_functions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\framework\\function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, input_shapes)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Add all function nodes to the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mimporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def_for_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# Initialize fields specific to FuncGraph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def_for_function\u001b[1;34m(graph_def, name)\u001b[0m\n\u001b[0;32m    410\u001b[0m   \u001b[1;34m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m   return _import_graph_def_internal(\n\u001b[1;32m--> 412\u001b[1;33m       graph_def, validate_colocation_constraints=False, name=name)\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[0;32m    492\u001b[0m   \u001b[1;31m# _ProcessNewOps.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mserialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializeToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[0;32m   1096\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[1;32m-> 1097\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mEncodeRepeatedField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEncodeRepeatedField\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mEncodeField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[0mvalue_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m       \u001b[0mentry_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m       \u001b[0mencode_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Softwares\\Conda\\envs\\tf3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpp_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_FieldDescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCPPTYPE_ENUM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m           \u001b[0mfield_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GetIntegerEnumValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menum_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "USE_MODULE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\" # updated the url to match tf2 requirements\n",
    "USE_EMBED = hub.load(USE_MODULE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_URL = 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
    "BERT_EMBED = hub.load(BERT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tokenization vocab file\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELMO_URL = 'https://tfhub.dev/google/elmo/3'\n",
    "ELMO_EMBED = hub.load(ELMO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path(df_path, rand=False, rand_seed=4079):\n",
    "    df = pd.read_csv(df_path)\n",
    "    if rand:\n",
    "        df = shuffle(df, random_state=rand_seed)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    df = load_from_path(path, rand=True)\n",
    "    df['id'] = df['id'].astype('category')\n",
    "    df['cat'] = df['cat'].astype('category')\n",
    "    df['doc'] = df['doc'].astype(str)\n",
    "    return df\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BERT(col_series):\n",
    "    def _create_tokenizer(vocab_file, do_lower_case=True):\n",
    "        return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "    # end def\n",
    "\n",
    "    # tokenizer = _create_tokenizer(os.path.join(os.environ['TFHUB_CACHE_DIR'], 'ecd2596ce849110246602e3d4d81e2d9719cb027/assets/vocab.txt'), do_lower_case=True\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    tokenizer = _create_tokenizer(vocab_file, do_lower_case=True)\n",
    "    # tokenizer = _create_tokenizer(os.path.join(os.environ['TFHUB_CACHE_DIR'], 'fcc4b13aa51839e09bd1c291f604abcc2411f245/assets/vocab.txt'), do_lower_case=True)\n",
    "\n",
    "    def _convert_sentence_to_bert(sentence, tokenizer, max_seq_len):\n",
    "        tokens = ['[CLS]']\n",
    "        tokens.extend(tokenizer.tokenize(sentence))\n",
    "        if len(tokens) > max_seq_len-1:\n",
    "            tokens = tokens[:max_seq_len-1]\n",
    "        tokens.append('[SEP]')\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        #Zero Mask till seq_length\n",
    "        zero_mask = [0] * (max_seq_len-len(tokens))\n",
    "        input_ids.extend(zero_mask)\n",
    "        input_mask.extend(zero_mask)\n",
    "        segment_ids.extend(zero_mask)\n",
    "        # pprint(input_ids)\n",
    "        # pprint(input_mask)\n",
    "        # pprint(segment_ids)\n",
    "        return input_ids, input_mask, segment_ids\n",
    "    # end def\n",
    "\n",
    "    def _convert_sentences_to_bert(sentences, tokenizer, max_seq_len=128):\n",
    "        all_input_ids = []\n",
    "        all_input_mask = []\n",
    "        all_segment_ids = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            input_ids, input_mask, segment_ids = _convert_sentence_to_bert(sentence, tokenizer, max_seq_len)\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_input_mask.append(input_mask)\n",
    "            all_segment_ids.append(segment_ids)\n",
    "\n",
    "        return all_input_ids, all_input_mask, all_segment_ids\n",
    "    # end def\n",
    "\n",
    "    pprint('Converting to BERT....')\n",
    "\n",
    "    # col_series = ['New Delhi is the capital of India', 'The capital of India is Delhi']\n",
    "    max_seq_len = 16\n",
    "    input_ids_vals, input_mask_vals, segment_ids_vals = _convert_sentences_to_bert(col_series, tokenizer, max_seq_len)\n",
    "    \n",
    "    '''bert_inputs = dict(\n",
    "    input_ids=tf.convert_to_tensor(input_ids_vals),\n",
    "    input_mask=tf.convert_to_tensor(input_mask_vals),\n",
    "    segment_ids=tf.convert_to_tensor(segment_ids_vals)\n",
    "    )'''\n",
    "    print(tf.shape(tf.convert_to_tensor(input_mask_vals)))\n",
    "    bert_outputs = BERT_EMBED.signatures['tokens'](input_ids=tf.convert_to_tensor(input_ids_vals),\n",
    "    input_mask=tf.convert_to_tensor(input_mask_vals),\n",
    "    segment_ids=tf.convert_to_tensor(segment_ids_vals))\n",
    "    # Note that out has 2 keys:\n",
    "    # sequence_output which is output embedding for each token and\n",
    "    # pooled_output which is output embedding for the entire sequence.\n",
    "\n",
    "    # return np.reshape(out['sequence_output'], (out['sequence_output'].shape[0], out['sequence_output'].shape[1] * out['sequence_output'].shape[2]))\n",
    "    return (bert_outputs['pooled_output'], bert_outputs['sequence_output'])\n",
    "    # return out['pooled_output']\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ELMO(col_series):\n",
    "    def _restric_len(sentence, max_seq_len=128):\n",
    "        tokens = word_tokenize(sentence)\n",
    "        if len(tokens) > max_seq_len:\n",
    "            tokens = tokens[:max_seq_len]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "    # end def\n",
    "\n",
    "    pprint('Converting to ELMO....')\n",
    "    max_seq_len = 128\n",
    "    # col_series = pd.Series(['New Delhi is the capital of India', 'The capital of India is Delhi'])\n",
    "    col_series = col_series.apply(lambda x: _restric_len(x, max_seq_len))\n",
    "    pprint(col_series)\n",
    "    elmo_inputs = {'tokens': tf.convert_to_tensor(col_series.values), \n",
    "                   'sequence_len' : 128}\n",
    "\n",
    "    pooled_embeddings = ELMO_EMBED.signatures['default'](text= tf.convert_to_tensor(col_series.values))['default']\n",
    "    seq_embeddings = ELMO_EMBED.signatures['default'](text= tf.convert_to_tensor(col_series.values))['elmo']\n",
    "    # return embeddings.reshape(embeddings.shape[0], embeddings.shape[1] * embeddings.shape[2])\n",
    "    return (pooled_embeddings, seq_embeddings)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Configs===================='\n",
      "'../data/20news/train.csv'\n",
      "'LABELED has 1123 data'\n",
      "'UNLABELED has 10191 data'\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# end with\n",
    "pprint('=' * 20 + 'Configs' + '=' * 20)\n",
    "pprint(config['train'])\n",
    "\n",
    "train_df = load_df(config['train'])\n",
    "test_df = load_df(config['test'])\n",
    "\n",
    "train_df['labeled'] = 0\n",
    "#### add x% of EACH CLASS in the train_df to L\n",
    "cat_count = Counter(train_df['cat'])\n",
    "random.seed(config['seed'])\n",
    "ratio = []\n",
    "for k, v in cat_count.items():\n",
    "    ratio.append(dict(k=v / train_df.shape[0]))\n",
    "    cat_id = list(train_df[train_df['cat'] == k]['id'].values)\n",
    "    rand_id = random.sample(cat_id, int(config['percent'] * v))  # x% currently 10%\n",
    "    train_df.loc[train_df['id'].isin(rand_id), 'labeled'] = 1\n",
    "# end for\n",
    "\n",
    "l_train_df = train_df.loc[train_df['labeled'] == 1]\n",
    "u_train_df = train_df.loc[train_df['labeled'] == 0]\n",
    "pprint('LABELED has {} data'.format(l_train_df.shape[0]))\n",
    "pprint('UNLABELED has {} data'.format(u_train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Embedding with doc2vec===================='\n"
     ]
    }
   ],
   "source": [
    "#embed all documents with doc2vec\n",
    "pprint('=' * 20 + 'Embedding with doc2vec' + '=' * 20)\n",
    "model = Doc2Vec.load(config['embed']['doc2vec_path'])\n",
    "l_train_doc2vec = np.array([model.infer_vector(doc.strip().split()) for doc in l_train_df['doc'].values])\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_doc2vec = np.array([model.infer_vector(doc.strip().split()) for doc in u_train_df['doc'].values])\n",
    "test_doc2vec = np.array([model.infer_vector(doc.strip().split()) for doc in test_df['doc'].values])\n",
    "pprint('DOC2VEC: Labeled training documents embedded into {} dimensions'.format(l_train_doc2vec.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('DOC2VEC: Unlabeled training documents embedded into {} dimensions'.format(u_train_doc2vec.shape))\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Embedding with tfidf===================='\n",
      "'TFIDF: Labeled training documents embedded into (1123, 10000) dimensions'\n",
      "'TFIDF: Unlabeled training documents embedded into (10191, 10000) dimensions'\n"
     ]
    }
   ],
   "source": [
    "#### embed all documents with tfidf\n",
    "pprint('=' * 20 + 'Embedding with tfidf' + '=' * 20)\n",
    "ngram_range = (1, 3)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{3,}',\n",
    "    ngram_range=ngram_range,\n",
    "    dtype=np.float32,\n",
    "    norm='l2',\n",
    "    min_df=3,\n",
    "    max_df=.9\n",
    "    )\n",
    "vectorizer.fit_transform(train_df['doc'])  # fit on all training documents, regardless of labeled or unlabeled\n",
    "\n",
    "l_train_tfidf_text = vectorizer.transform(l_train_df['doc']).toarray()\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_tfidf_text = vectorizer.transform(u_train_df['doc']).toarray()\n",
    "test_tfidf_text = vectorizer.transform(test_df['doc']).toarray()\n",
    "\n",
    "pprint('TFIDF: Labeled training documents embedded into {} dimensions'.format(l_train_tfidf_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('TFIDF: Unlabeled training documents embedded into {} dimensions'.format(u_train_tfidf_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================USE===================='\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'USE_EMBED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-502a85c2c1b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'USE'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ml_train_use_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUSE_EMBED\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'doc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mu_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mu_train_use_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUSE_EMBED\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'doc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'USE_EMBED' is not defined"
     ]
    }
   ],
   "source": [
    "#### embed all documents with USE\n",
    "pprint('=' * 20 + 'USE' + '=' * 20)\n",
    "\n",
    "l_train_use_text = USE_EMBED(l_train_df['doc']).numpy()\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_use_text = USE_EMBED(u_train_df['doc']).numpy()\n",
    "test_use_text = USE_EMBED(test_df['doc']).numpy()\n",
    "#end with\n",
    "\n",
    "pprint('USE: Labeled training documents embedded into {} dimensions'.format(l_train_use_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('USE: Unlabeled training documents embedded into {} dimensions'.format(u_train_use_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================BERT===================='\n",
      "'Converting to BERT....'\n",
      "tf.Tensor([1123   16], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#### embed all documents with BERT\n",
    "tf.keras.backend.set_floatx('float16')\n",
    "pprint('=' * 20 + 'BERT' + '=' * 20)\n",
    "l_train_pooledbert_text, l_train_seqbert_text = get_BERT(l_train_df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Converting to BERT....'\n",
      "tf.Tensor([10191    16], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"): # OOR error due to lack of memory resource, change to CPU compute\n",
    "    if u_train_df.shape[0] > 0:\n",
    "        u_train_pooledbert_text, u_train_seqbert_text = get_BERT(u_train_df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Converting to BERT....'\n",
      "tf.Tensor([7532   16], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    test_pooledbert_text, test_seqbert_text = get_BERT(test_df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_train_pooledbert_text = l_train_pooledbert_text.numpy()\n",
    "l_train_seqbert_text = l_train_seqbert_text.numpy()\n",
    "u_train_pooledbert_text = u_train_pooledbert_text.numpy()\n",
    "u_train_seqbert_text = u_train_seqbert_text.numpy()\n",
    "test_pooledbert_text = test_pooledbert_text.numpy()\n",
    "test_seqbert_text = test_seqbert_text.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### embed all documents with ELMO\n",
    "# Config threading params\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    pprint('=' * 20 + 'ELMO' + '=' * 20)\n",
    "    l_train_pooledelmo_text, l_train_seqelmo_text = get_ELMO(l_train_df['doc'])\n",
    "    if u_train_df.shape[0] > 0:\n",
    "        u_train_pooledelmo_text, u_train_seqelmo_text = get_ELMO(u_train_df['doc'])\n",
    "    test_pooledelmo_text, test_seqelmo_text = get_ELMO(test_df['doc'], session)\n",
    "#end with\n",
    "\n",
    "pprint('POOLEDELMO: Labeled training documents embedded into {} dimensions'.format(l_train_pooledelmo_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('POOLEDELMO: Unlabeled training documents embedded into {} dimensions'.format(u_train_pooledelmo_text.shape))\n",
    "\n",
    "pprint('SEQELMO: Labeled training documents embedded into {} dimensions'.format(l_train_seqelmo_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('SEQELMO: Unlabeled training documents embedded into {} dimensions'.format(u_train_seqelmo_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Binarized Classes: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\\n\"\n",
      " \" 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\\n\"\n",
      " \" 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\\n\"\n",
      " \" 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\\n\"\n",
      " \" 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\\n\"\n",
      " \" 'talk.politics.misc' 'talk.religion.misc']\")\n",
      "(\"Encoded Classes: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\\n\"\n",
      " \" 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\\n\"\n",
      " \" 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\\n\"\n",
      " \" 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\\n\"\n",
      " \" 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\\n\"\n",
      " \" 'talk.politics.misc' 'talk.religion.misc']\")\n"
     ]
    }
   ],
   "source": [
    "#### binarize train target\n",
    "lb = LabelBinarizer().fit(train_df['cat'].values)\n",
    "l_train_cat_bin = lb.transform(l_train_df['cat'].values)\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_cat_bin = lb.transform(u_train_df['cat'].values)\n",
    "pprint('Binarized Classes: {}'.format(lb.classes_))\n",
    "#### binarize test target\n",
    "test_cat_bin = lb.transform(test_df['cat'].values)\n",
    "\n",
    "#### encode train target\n",
    "le = LabelEncoder().fit(train_df['cat'].values)\n",
    "l_train_cat_en = le.transform(l_train_df['cat'].values)\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_cat_en = le.transform(u_train_df['cat'].values)\n",
    "pprint('Encoded Classes: {}'.format(le.classes_))\n",
    "#### encode test target\n",
    "test_cat_en = le.transform(test_df['cat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save all embedded documents\n",
    "#### save labeled train data to output path\n",
    "if config['labeled_train_out']:\n",
    "    l_train_data = [\n",
    "        dict(\n",
    "            # fasttext=l_train_fasttext_text[i],\n",
    "            # pooledbiobert=l_train_pooledbiobert_text[i],\n",
    "            # seqbiobert=l_train_seqbiobert_text[i],\n",
    "            # tfidf=l_train_tfidf_text[i],\n",
    "            # doc2vec=l_train_doc2vec[i],\n",
    "            # use=l_train_use_text[i],\n",
    "            pooledbert=l_train_pooledbert_text[i],\n",
    "            seqbert=l_train_seqbert_text[i],\n",
    "            # pooledelmo=l_train_pooledelmo_text[i],\n",
    "            # seqelmo=l_train_seqelmo_text[i],\n",
    "            cat_bin=label,\n",
    "            cat_en=l_train_cat_en[i],\n",
    "            id=l_train_df['id'].values[i])\n",
    "        for i, label in enumerate(l_train_cat_bin)]\n",
    "    joblib.dump(\n",
    "        l_train_data,\n",
    "        config['labeled_train_out'],\n",
    "        compress=3)\n",
    "# end if\n",
    "\n",
    "#### save unlabeled train data to output path\n",
    "if config['unlabeled_train_out'] and u_train_df.shape[0] > 0:\n",
    "    u_train_data = [\n",
    "        dict(\n",
    "            # fasttext=u_train_fasttext_text[i],\n",
    "            # pooledbiobert=u_train_pooledbiobert_text[i],\n",
    "            # seqbiobert=u_train_seqbiobert_text[i],\n",
    "            # tfidf=u_train_tfidf_text[i],\n",
    "            # doc2vec=u_train_doc2vec[i],\n",
    "            # use=u_train_use_text[i],\n",
    "            pooledbert=u_train_pooledbert_text[i],\n",
    "            seqbert=u_train_seqbert_text[i],\n",
    "            # pooledelmo=u_train_pooledelmo_text[i],\n",
    "            # seqelmo=u_train_seqelmo_text[i],\n",
    "            cat_bin=label,\n",
    "            cat_en=u_train_cat_en[i],\n",
    "            id=u_train_df['id'].values[i])\n",
    "        for i, label in enumerate(u_train_cat_bin)]\n",
    "    joblib.dump(\n",
    "        u_train_data,\n",
    "        config['unlabeled_train_out'],\n",
    "        compress=3)\n",
    "# end if\n",
    "\n",
    "if config['test_out']:\n",
    "    test_data = [\n",
    "        dict(\n",
    "            # fasttext=test_fasttext_text[i],\n",
    "            # pooledbiobert=test_pooledbiobert_text[i],\n",
    "            # seqbiobert=test_seqbiobert_text[i],\n",
    "            # tfidf=test_tfidf_text[i],\n",
    "            # doc2vec=test_doc2vec[i],\n",
    "            # use=test_use_text[i],\n",
    "            pooledbert=test_pooledbert_text[i],\n",
    "            seqbert=test_seqbert_text[i],\n",
    "            # pooledelmo=test_pooledelmo_text[i],\n",
    "            # seqelmo=test_seqelmo_text[i],\n",
    "            cat_bin=label,\n",
    "            cat_en=test_cat_en[i],\n",
    "            id=test_df['id'].values[i])\n",
    "        for i, label in enumerate(test_cat_bin)]\n",
    "    joblib.dump(\n",
    "        test_data,\n",
    "        config['test_out'],\n",
    "        compress=3)\n",
    "# end if\n",
    "\n",
    "#### save binarizer to output path\n",
    "if config['encoder_out']:\n",
    "    joblib.dump(\n",
    "        le,\n",
    "        config['encoder_out'],\n",
    "        compress=3)\n",
    "\n",
    "#### save encoder to output path\n",
    "if config['binarizer_out']:\n",
    "    joblib.dump(\n",
    "        lb,\n",
    "        config['binarizer_out'],\n",
    "        compress=3)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7676421  -0.46616325 -0.80833274  0.6734823   0.33734703 -0.27703196\n",
      "  0.60597163  0.5224088  -0.8149108  -0.9998391  -0.4292998   0.9429371\n",
      "  0.9663594   0.3679517   0.5756684  -0.8142145  -0.59017307 -0.43645248\n",
      "  0.42589492 -0.14058141  0.55344635  0.99997294 -0.32688245  0.4266491\n",
      "  0.50261784  0.9815946  -0.82330453  0.7125289   0.9123911   0.56843674\n",
      " -0.592455    0.49326822 -0.98284304 -0.20813778 -0.89326036 -0.9788771\n",
      "  0.38495365 -0.26637498 -0.10426681 -0.01124939 -0.4199149   0.45385128\n",
      "  0.9997956  -0.06899013  0.46134266 -0.3337812  -0.9999993   0.28515524\n",
      " -0.6364738   0.81394595  0.869247    0.88619417  0.35010263  0.4629448\n",
      "  0.59282386 -0.44816735  0.02279369  0.38343647 -0.2338827  -0.55296415\n",
      " -0.62468624  0.627178   -0.8014105  -0.75086355  0.950226    0.5828002\n",
      " -0.49729773 -0.3209368  -0.10257295 -0.12500489  0.6877629   0.23662205\n",
      "  0.01854715 -0.74639153  0.7118426   0.27826643 -0.68398416  1.\n",
      " -0.72101104 -0.9403801   0.8814371   0.6914073   0.685079   -0.2502103\n",
      "  0.41625664 -1.          0.44488567 -0.13446106 -0.95374817  0.33094475\n",
      "  0.6599405  -0.12986284  0.60307187  0.647164   -0.50742406 -0.6042346\n",
      " -0.23436192 -0.74435264 -0.35202172 -0.6516046   0.15946881 -0.38825443\n",
      " -0.4634508  -0.3785547   0.44002908 -0.56068206 -0.21799962  0.33685127\n",
      "  0.32913822  0.69502705  0.5351068  -0.36473632  0.57977045 -0.9090637\n",
      "  0.64064986 -0.3296584  -0.95773304 -0.7145508  -0.96360457  0.47758898\n",
      " -0.14330295 -0.4876815   0.7224218  -0.6382026   0.49349564 -0.38735092\n",
      " -0.8984786  -1.         -0.8274008  -0.73784065 -0.07400199 -0.31894016\n",
      " -0.9455302  -0.919209    0.5518437   0.78886235  0.25921616  0.9992662\n",
      " -0.44265133  0.8659471  -0.32666457 -0.7622578   0.6326302  -0.37933764\n",
      "  0.86583495  0.24349885 -0.21450683  0.33778667 -0.5569703   0.52570164\n",
      " -0.73216593 -0.51870275 -0.6658253  -0.66555595 -0.4561733   0.80929875\n",
      " -0.341575   -0.87866414 -0.12469736 -0.45568797 -0.51150817  0.64476323\n",
      "  0.7469412   0.5462793  -0.48713738  0.4667162   0.23856343  0.4701308\n",
      " -0.65341187 -0.41550633  0.43936077 -0.41392812 -0.83150893 -0.9474356\n",
      " -0.44940498  0.3852029   0.949585    0.45167902  0.33413324  0.7580787\n",
      " -0.30797067  0.71382725 -0.91539866  0.9598908  -0.17579523  0.34535137\n",
      " -0.43702325  0.3433509  -0.60580426 -0.08973318  0.7081305  -0.6879267\n",
      " -0.58738995 -0.14790134 -0.49623686 -0.5020775  -0.7298504   0.3643522\n",
      " -0.42908326 -0.4082329  -0.13979387  0.75813323  0.8445579   0.42350233\n",
      "  0.63539255  0.49569482 -0.46319753 -0.30287254  0.38176632  0.30231085\n",
      "  0.13902701  0.97045016 -0.7413244  -0.08321175 -0.73727924 -0.9438921\n",
      "  0.10065097 -0.6690084  -0.18412374 -0.61909163  0.702719   -0.3629818\n",
      "  0.3555758   0.35781425 -0.39367852 -0.727701    0.37703574 -0.4630602\n",
      "  0.56056964 -0.3841393   0.9653545   0.8780598  -0.60318977  0.4323298\n",
      "  0.8824058  -0.76437235 -0.63615036  0.26308295 -0.39180285  0.75936633\n",
      " -0.6901826   0.94812804  0.93292564  0.7279678  -0.7594254  -0.80889183\n",
      " -0.41779554 -0.68681854 -0.39899188  0.02908763  0.86580545  0.6581602\n",
      "  0.54539967  0.4280377  -0.77022105  0.9061541  -0.972128   -0.909676\n",
      " -0.8068835  -0.38256365 -0.9692659   0.8373333   0.4433394   0.4842536\n",
      " -0.5801909  -0.52479315 -0.8737474   0.61376476  0.19363435  0.83650875\n",
      " -0.5015391  -0.8605542  -0.70037264 -0.82703066  0.00566236 -0.29123884\n",
      " -0.33950758  0.08890852 -0.7739828   0.7019687   0.43036357  0.40344805\n",
      " -0.8022756   0.97733605  1.          0.9436669   0.65802544  0.2966222\n",
      " -0.9998995  -0.73736626  0.99991536 -0.9842122  -1.         -0.74166685\n",
      " -0.7600115   0.09547334 -1.         -0.32115284 -0.18199527 -0.70538974\n",
      "  0.7022419   0.9303708   0.8318905  -1.          0.54480225  0.7547986\n",
      " -0.71978486  0.94398326 -0.6154937   0.9316356   0.30245787  0.64627695\n",
      " -0.231441    0.53272676 -0.9042622  -0.7933066  -0.6299875  -0.642313\n",
      "  0.9979982   0.29879874 -0.735296   -0.55669856  0.54091924 -0.51527613\n",
      "  0.04792108 -0.89456064 -0.3724175   0.6705214   0.77056307  0.26121473\n",
      "  0.49332944 -0.61870104  0.2616715   0.03580729 -0.03777068  0.70908964\n",
      " -0.76934433 -0.06196601 -0.14469747  0.3711539  -0.6758801  -0.89089334\n",
      "  0.85671085 -0.2717058   0.8987185   1.          0.7718624  -0.377116\n",
      "  0.7395095   0.31133738 -0.582151    1.          0.8606386  -0.9396628\n",
      " -0.72633535  0.4932737  -0.6294073  -0.6659951   0.99586254 -0.3458831\n",
      " -0.8301117  -0.72866803  0.9484478  -0.98289835  0.984031   -0.6696164\n",
      " -0.89113057  0.85979766  0.7849114  -0.6396497  -0.28733966  0.3748135\n",
      " -0.6078098   0.44059294 -0.61662686  0.8332731   0.33540845 -0.23390557\n",
      "  0.6744502  -0.6716683  -0.56782585  0.4001462  -0.7753835  -0.35286638\n",
      "  0.91573584  0.44251597 -0.36846435  0.05888737 -0.55473125 -0.8647931\n",
      " -0.8184029   0.58276135  1.         -0.51401097  0.76533425 -0.43681592\n",
      " -0.11164058 -0.00404679  0.5494495   0.636428   -0.41746065 -0.4272302\n",
      "  0.6315526  -0.8296341  -0.9747658   0.24467836  0.412419   -0.31565017\n",
      "  0.99997294  0.6717639   0.30800042  0.30658066  0.9775041   0.22372617\n",
      " -0.04838966  0.8022227   0.95786667 -0.5234907   0.7005833   0.3473515\n",
      " -0.838602   -0.48693752 -0.43065208  0.08453466 -0.8529281   0.05805722\n",
      " -0.89643025  0.9134579   0.9139184   0.3338897   0.3532778   0.7180616\n",
      "  1.         -0.9249005   0.42934898  0.1645014   0.5236906  -0.99882686\n",
      " -0.42640525 -0.51410353 -0.2643002  -0.7784773  -0.4019702   0.25253332\n",
      " -0.8693502   0.77742344  0.6891711  -0.75666624 -0.9707906  -0.4871738\n",
      "  0.81818885  0.28313616 -0.9784789  -0.7384329  -0.44218886  0.6904579\n",
      " -0.36966482 -0.86780524 -0.25378203 -0.3940662   0.6561825  -0.44821715\n",
      "  0.67546546  0.8471017   0.71066064 -0.5983696  -0.5426468  -0.22168683\n",
      " -0.6346737   0.847336   -0.59304655 -0.93173265 -0.19515948  1.\n",
      " -0.6462903   0.81912535  0.61305887  0.2915688  -0.5013205   0.36295152\n",
      "  0.8412618   0.53180575 -0.56347984 -0.83426815  0.12672193 -0.6022504\n",
      "  0.6310681   0.67490464  0.623592    0.45662886  0.7794415   0.3663977\n",
      " -0.25397816  0.11453048  0.9785388  -0.33401135 -0.3666535  -0.5417891\n",
      " -0.3562715  -0.43378004  0.02096787  1.          0.26430392  0.6534188\n",
      " -0.9823204  -0.8989292  -0.7034719   0.99999946  0.74599487 -0.34520614\n",
      "  0.63686925  0.6849058  -0.40201142  0.47445798 -0.39059174 -0.32078838\n",
      "  0.47079676  0.1891589   0.85069007 -0.58755577 -0.9401344  -0.42795992\n",
      "  0.47616163 -0.8010019   0.9999014  -0.6029571  -0.32578805 -0.35244057\n",
      " -0.56282634 -0.30707362 -0.01645462 -0.918255   -0.38360426  0.3088512\n",
      "  0.86871076  0.3494363  -0.7606926  -0.62847507  0.856807    0.7841141\n",
      " -0.93151104 -0.8237482   0.88306737 -0.8555387   0.71404266  1.\n",
      "  0.50318176  0.54615295  0.33299112 -0.4421312   0.22428724 -0.59232104\n",
      "  0.59000397 -0.80990493 -0.37609184 -0.24676518  0.3980707  -0.17006576\n",
      " -0.9114288   0.59935987  0.22500648 -0.7161157  -0.67139167 -0.21697241\n",
      "  0.5582673   0.82636756 -0.21067208 -0.23739204  0.31630993 -0.2121971\n",
      " -0.5909293  -0.5590089  -0.49943498 -0.9999815   0.46893722 -1.\n",
      "  0.49431652  0.2464011  -0.33889842  0.47853217  0.6341933   0.45265907\n",
      " -0.49087486 -0.7692401   0.3206222   0.52360415 -0.33147097 -0.72235197\n",
      " -0.5260172   0.31617448 -0.22226171  0.2622123  -0.7853646   0.6330575\n",
      " -0.38101292  1.          0.15839694 -0.84233296 -0.6169152   0.35631055\n",
      " -0.5325755   1.         -0.44175804 -0.91827834  0.46821415 -0.7246098\n",
      " -0.50384057  0.5465791   0.36557114 -0.84073067 -0.9509226   0.558901\n",
      "  0.7380229  -0.7283629   0.69179577 -0.42704377 -0.39748406  0.30979267\n",
      "  0.8372868   0.94769424  0.49702796  0.6028396  -0.59723395 -0.4275095\n",
      "  0.8266412   0.4365967  -0.00939885  0.34760106  1.          0.38150927\n",
      " -0.8441633  -0.28377873 -0.78035736 -0.37947968 -0.80054873  0.36916575\n",
      "  0.40926188  0.79777044 -0.34695277  0.8705158  -0.78272754  0.19463824\n",
      " -0.69361824 -0.50174236  0.5682623  -0.6737287  -0.95707536 -0.95334506\n",
      "  0.6307295  -0.43464932  0.01824553  0.4551125   0.22965965  0.5003441\n",
      "  0.52941996 -1.          0.7176367   0.55771935  0.8621963   0.9088933\n",
      "  0.60897267  0.6538755   0.4498386  -0.9339216  -0.39684752 -0.42875788\n",
      " -0.33160767  0.58044744  0.7762059   0.63863456  0.4707335  -0.43511766\n",
      " -0.5029546  -0.57235146 -0.9298913  -0.9628881   0.4237334  -0.63402694\n",
      " -0.6168658   0.8991013  -0.4527899  -0.1130069  -0.22778775 -0.66651434\n",
      "  0.09572566  0.18379515  0.09049439  0.12399108  0.31130674  0.66749954\n",
      "  0.8646439   0.96562624 -0.85643613  0.39132738 -0.61148643  0.44951054\n",
      "  0.934834   -0.874255    0.41759965  0.47435522 -0.44571295  0.40600568\n",
      " -0.42300206 -0.41980678  0.8659491  -0.37446782  0.5236276  -0.4125554\n",
      " -0.08719008 -0.3250077  -0.36570454 -0.35013726 -0.6438646   0.75571465\n",
      "  0.20065448  0.7245705   0.8484181  -0.2156786  -0.6196522  -0.31378588\n",
      " -0.70713866 -0.78132874  0.44172454 -0.18218297 -0.09446708  0.4742036\n",
      "  0.11201043  0.92519766  0.44957525 -0.5783047  -0.4105299  -0.69158274\n",
      "  0.6031692  -0.76071745 -0.64548385 -0.6573058   0.6599412   0.5032136\n",
      "  0.99998254 -0.80281335 -0.90786165 -0.5197456  -0.3163534   0.5108397\n",
      " -0.68570566 -1.          0.31457865 -0.52028966  0.7147783  -0.71586907\n",
      "  0.70395666 -0.70211333 -0.71629107 -0.40618968  0.6442961   0.71094584\n",
      " -0.59705734 -0.6721504   0.61363554 -0.5876238   0.9711907   0.64339197\n",
      " -0.8280055  -0.03593563  0.7373143  -0.6367786  -0.6208157   0.40780976]\n",
      "(768,)\n",
      "[ 2.80667245e-02 -1.04035087e-01  3.11075361e-03 -6.97779581e-02\n",
      " -7.04312250e-02 -6.61405176e-02  8.81386921e-02  2.48206779e-02\n",
      " -4.25062478e-02  8.18586871e-02 -9.56595019e-02 -1.14025749e-01\n",
      " -3.22008021e-02 -1.47503652e-02  6.30101636e-02  1.26374930e-01\n",
      "  3.23318411e-03 -3.62728350e-02  3.35823298e-02  1.98602164e-03\n",
      "  8.00993070e-02  4.43975143e-02  1.38772845e-01  1.21240027e-01\n",
      "  7.37969503e-02  2.44122744e-02  1.29118279e-01 -9.97334346e-03\n",
      " -2.76761293e-01 -3.45095783e-01  2.48508602e-02  1.62384450e-01\n",
      " -1.34924188e-01 -5.53352199e-02 -5.42060807e-02  5.54349972e-04\n",
      "  1.53746977e-01 -8.74958411e-02 -1.96109027e-01  3.80479381e-04\n",
      " -7.43817212e-03  1.76583841e-01  1.05221719e-01 -6.65107444e-02\n",
      " -8.59641284e-03 -8.27623531e-03 -6.74328208e-02  4.75037880e-02\n",
      "  6.16093390e-02 -2.40543246e-01 -2.22888485e-01  4.46164161e-02\n",
      "  6.46176338e-02 -8.04448798e-02 -6.13952614e-02 -2.15818658e-02\n",
      "  4.48692776e-02  1.13145858e-01 -8.37044045e-02 -1.93139259e-02\n",
      " -1.42067820e-01 -8.73204693e-02  1.05288532e-03 -1.90394089e-01\n",
      "  1.20927282e-01 -1.84746329e-02 -1.17971294e-01 -4.48223710e-01\n",
      "  2.16753557e-02 -6.89936057e-02  9.34753641e-02  8.82934406e-02\n",
      " -1.44770425e-02  3.35181877e-02 -1.60452440e-01 -8.47856700e-03\n",
      " -9.74877924e-02  1.26541212e-01  9.28966179e-02 -1.49272650e-01\n",
      " -2.18501571e-03  3.55611071e-02  2.09059343e-02 -1.16735592e-01\n",
      " -1.05022222e-01 -1.81282368e-02 -2.15079501e-01 -3.10987867e-02\n",
      " -5.28731868e-02 -5.28164096e-02  7.38760233e-02 -1.56061038e-01\n",
      "  1.42168894e-01  5.57508804e-02 -1.33661985e-01  6.37765694e-03\n",
      "  3.07172686e-02  1.77091900e-02 -4.98592779e-02 -1.20700262e-01\n",
      " -1.39251828e-01  2.44529359e-02 -1.10145420e-01  9.80330333e-02\n",
      "  6.74571767e-02  7.97298551e-02  1.99006777e-02  1.02888040e-01\n",
      " -6.49648830e-02 -8.27350542e-02 -4.12138253e-02 -2.51652062e-01\n",
      "  5.00064269e-02  1.44670466e-02 -1.03918195e-01 -2.47386396e-01\n",
      "  4.92148064e-02  1.27326056e-01  1.44724235e-01 -6.11720867e-02\n",
      " -2.26067454e-02 -2.26092651e-01 -6.01326860e-03  8.26706924e-03\n",
      " -1.04600012e-01  9.96696576e-02 -2.25229442e-01 -2.01293826e-01\n",
      "  2.35043112e-02  1.89880580e-02 -2.74508484e-02  1.58254698e-01\n",
      "  2.66336892e-02 -1.72480971e-01 -3.75909582e-02 -7.86091313e-02\n",
      " -1.60942987e-01  4.24774438e-02  1.76562041e-01 -7.14443028e-02\n",
      "  8.34411606e-02  1.36869296e-01  1.43565997e-01 -1.00944154e-01\n",
      " -5.92343137e-02  2.36561708e-02  1.71262160e-01  2.54650731e-02\n",
      "  7.67739117e-02 -4.68097255e-02 -1.11939043e-01  7.71979839e-02\n",
      "  1.15993455e-01 -6.40464127e-02  9.88402143e-02  1.13342246e-02\n",
      "  2.54381467e-02 -9.69957933e-02 -1.43334106e-01 -8.74643549e-02\n",
      "  1.27799571e-01  8.86284038e-02  2.48592719e-01  5.35499677e-02\n",
      " -7.91798159e-02 -3.21363844e-02 -8.48290250e-02  5.91310964e-04\n",
      "  1.69342801e-01 -1.42842792e-02 -3.79764847e-02  6.14692308e-02\n",
      " -2.84493174e-02 -2.92886198e-01  1.17988475e-01 -8.36173370e-02\n",
      " -4.87950370e-02  5.11263758e-02 -1.57659370e-02 -8.57241377e-02\n",
      " -3.09331995e-02  1.67490482e-01  4.45871465e-02 -2.10781872e-01\n",
      "  1.17815323e-01  1.19980663e-01  1.51114203e-02  9.34701264e-02\n",
      "  8.75532511e-04  9.53624994e-02 -6.20280718e-03 -2.38869429e-01\n",
      "  1.76365033e-01  1.84925184e-01  1.13929763e-01 -6.34442121e-02\n",
      "  3.82464305e-02  7.62148499e-02 -1.30877733e-01 -5.27434163e-02\n",
      " -1.02403015e-01 -9.01833177e-02 -9.12459865e-02 -1.48272663e-01\n",
      " -7.82167241e-02  2.08586439e-01 -1.27854452e-01  2.77103812e-01\n",
      "  7.77238011e-02 -1.02604367e-02  6.43515736e-02  2.17205435e-02\n",
      " -7.02160522e-02 -1.00145256e-02 -1.84019715e-01  1.00615129e-01\n",
      " -8.14162791e-02 -1.57172084e-01  1.60925034e-02 -1.60665512e-01\n",
      "  3.52676697e-02 -2.48589795e-02 -5.79994991e-02 -5.41976131e-02\n",
      " -2.01351508e-01 -4.79763467e-03 -1.39805660e-01 -5.62499128e-02\n",
      "  8.88322368e-02  5.91710694e-02  1.80647299e-01 -8.18449184e-02\n",
      "  2.12323993e-01 -4.33112234e-02  3.59843560e-02  5.93333729e-02\n",
      "  1.01892442e-01 -8.36398453e-02 -2.46636607e-02  8.74939561e-02\n",
      " -6.93922937e-02  5.68383411e-02  7.11226389e-02 -2.42712021e-01\n",
      " -1.83594413e-02 -1.35829598e-01  6.03395849e-02 -6.06551766e-02\n",
      " -1.68852046e-01 -9.37248096e-02 -9.85014662e-02  1.45006612e-01\n",
      "  6.75429478e-02 -7.06535876e-02 -7.31469840e-02 -1.10102728e-01\n",
      "  3.86839993e-02 -1.87656760e-01  9.12354589e-02 -9.20875892e-02\n",
      "  1.93247437e-01 -7.20688775e-02 -1.69017568e-01 -8.10754448e-02\n",
      " -1.09715359e-02  6.55665770e-02 -2.97056902e-02 -5.10690473e-02\n",
      "  2.00821787e-01  6.29581809e-02  7.03147873e-02  6.82810098e-02\n",
      "  9.40756351e-02  3.81153792e-01 -8.67910013e-02 -1.68832913e-01\n",
      "  1.18505724e-01 -3.67909670e-02  2.77958438e-02 -5.88753074e-02\n",
      " -1.93371564e-01  7.96623621e-03 -9.99538321e-03  1.04772352e-01\n",
      "  2.36882865e-01 -8.89882892e-02 -9.48018432e-02 -2.32223332e-01\n",
      "  1.84241068e-02 -1.90103650e-01  3.01730204e-02  1.90392941e-01\n",
      " -2.19782796e-02 -2.47915101e-04  1.38278618e-01 -2.00979441e-01\n",
      "  2.01861504e-02  2.00568497e-01 -1.06333807e-01  1.03739746e-01]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[20]['seqbert'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
