{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "# Config threading params\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "config_path = '../config/20news.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "USE_MODULE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\" # updated the url to match tf2 requirements\n",
    "USE_EMBED = hub.load(USE_MODULE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_URL = 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
    "BERT_EMBED = hub.load(BERT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tokenization vocab file\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELMO_URL = 'https://tfhub.dev/google/elmo/3'\n",
    "ELMO_EMBED = hub.load(ELMO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path(df_path, rand=False, rand_seed=4079):\n",
    "    df = pd.read_csv(df_path)\n",
    "    if rand:\n",
    "        df = shuffle(df, random_state=rand_seed)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    df = load_from_path(path, rand=True)\n",
    "    df['id'] = df['id'].astype('category')\n",
    "    df['cat'] = df['cat'].astype('category')\n",
    "    df['doc'] = df['doc'].astype(str)\n",
    "    return df\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BERT(col_series):\n",
    "    def _create_tokenizer(vocab_file, do_lower_case=True):\n",
    "        return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "    # end def\n",
    "\n",
    "    # tokenizer = _create_tokenizer(os.path.join(os.environ['TFHUB_CACHE_DIR'], 'ecd2596ce849110246602e3d4d81e2d9719cb027/assets/vocab.txt'), do_lower_case=True\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    tokenizer = _create_tokenizer(vocab_file, do_lower_case=True)\n",
    "    # tokenizer = _create_tokenizer(os.path.join(os.environ['TFHUB_CACHE_DIR'], 'fcc4b13aa51839e09bd1c291f604abcc2411f245/assets/vocab.txt'), do_lower_case=True)\n",
    "\n",
    "    def _convert_sentence_to_bert(sentence, tokenizer, max_seq_len):\n",
    "        tokens = ['[CLS]']\n",
    "        tokens.extend(tokenizer.tokenize(sentence))\n",
    "        if len(tokens) > max_seq_len-1:\n",
    "            tokens = tokens[:max_seq_len-1]\n",
    "        tokens.append('[SEP]')\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        #Zero Mask till seq_length\n",
    "        zero_mask = [0] * (max_seq_len-len(tokens))\n",
    "        input_ids.extend(zero_mask)\n",
    "        input_mask.extend(zero_mask)\n",
    "        segment_ids.extend(zero_mask)\n",
    "        # pprint(input_ids)\n",
    "        # pprint(input_mask)\n",
    "        # pprint(segment_ids)\n",
    "        return input_ids, input_mask, segment_ids\n",
    "    # end def\n",
    "\n",
    "    def _convert_sentences_to_bert(sentences, tokenizer, max_seq_len=128):\n",
    "        all_input_ids = []\n",
    "        all_input_mask = []\n",
    "        all_segment_ids = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            input_ids, input_mask, segment_ids = _convert_sentence_to_bert(sentence, tokenizer, max_seq_len)\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_input_mask.append(input_mask)\n",
    "            all_segment_ids.append(segment_ids)\n",
    "\n",
    "        return all_input_ids, all_input_mask, all_segment_ids\n",
    "    # end def\n",
    "\n",
    "    pprint('Converting to BERT....')\n",
    "\n",
    "    # col_series = ['New Delhi is the capital of India', 'The capital of India is Delhi']\n",
    "    max_seq_len = 16\n",
    "    input_ids_vals, input_mask_vals, segment_ids_vals = _convert_sentences_to_bert(col_series, tokenizer, max_seq_len)\n",
    "    \n",
    "    '''bert_inputs = dict(\n",
    "    input_ids=tf.convert_to_tensor(input_ids_vals),\n",
    "    input_mask=tf.convert_to_tensor(input_mask_vals),\n",
    "    segment_ids=tf.convert_to_tensor(segment_ids_vals)\n",
    "    )'''\n",
    "    print(tf.shape(tf.convert_to_tensor(input_mask_vals)))\n",
    "    bert_outputs = BERT_EMBED.signatures['tokens'](input_ids=tf.convert_to_tensor(input_ids_vals),\n",
    "    input_mask=tf.convert_to_tensor(input_mask_vals),\n",
    "    segment_ids=tf.convert_to_tensor(segment_ids_vals))\n",
    "    # Note that out has 2 keys:\n",
    "    # sequence_output which is output embedding for each token and\n",
    "    # pooled_output which is output embedding for the entire sequence.\n",
    "\n",
    "    # return np.reshape(out['sequence_output'], (out['sequence_output'].shape[0], out['sequence_output'].shape[1] * out['sequence_output'].shape[2]))\n",
    "    return (bert_outputs['pooled_output'], bert_outputs['sequence_output'])\n",
    "    # return out['pooled_output']\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ELMO(col_series):\n",
    "    def _restric_len(sentence, max_seq_len=128):\n",
    "        tokens = word_tokenize(sentence)\n",
    "        if len(tokens) > max_seq_len:\n",
    "            tokens = tokens[:max_seq_len]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "    # end def\n",
    "\n",
    "    pprint('Converting to ELMO....')\n",
    "    max_seq_len = 128\n",
    "    # col_series = pd.Series(['New Delhi is the capital of India', 'The capital of India is Delhi'])\n",
    "    col_series = col_series.apply(lambda x: _restric_len(x, max_seq_len))\n",
    "    elmo_inputs = {'tokens': tf.convert_to_tensor(col_series.values), \n",
    "                   'sequence_len' : 128}\n",
    "\n",
    "    pooled_embeddings = ELMO_EMBED.signatures['default'](text= tf.convert_to_tensor(col_series.values))['default']\n",
    "    seq_embeddings = ELMO_EMBED.signatures['default'](text= tf.convert_to_tensor(col_series.values))['elmo']\n",
    "    # return embeddings.reshape(embeddings.shape[0], embeddings.shape[1] * embeddings.shape[2])\n",
    "    return (pooled_embeddings, seq_embeddings)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Configs===================='\n",
      "'../data/20news/train.csv'\n",
      "'LABELED has 1123 data'\n",
      "'UNLABELED has 10191 data'\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# end with\n",
    "pprint('=' * 20 + 'Configs' + '=' * 20)\n",
    "pprint(config['train'])\n",
    "\n",
    "train_df = load_df(config['train'])\n",
    "test_df = load_df(config['test'])\n",
    "\n",
    "train_df['labeled'] = 0\n",
    "#### add x% of EACH CLASS in the train_df to L\n",
    "cat_count = Counter(train_df['cat'])\n",
    "random.seed(config['seed'])\n",
    "ratio = []\n",
    "for k, v in cat_count.items():\n",
    "    ratio.append(dict(k=v / train_df.shape[0]))\n",
    "    cat_id = list(train_df[train_df['cat'] == k]['id'].values)\n",
    "    rand_id = random.sample(cat_id, int(config['percent'] * v))  # x% currently 10%\n",
    "    train_df.loc[train_df['id'].isin(rand_id), 'labeled'] = 1\n",
    "# end for\n",
    "\n",
    "l_train_df = train_df.loc[train_df['labeled'] == 1]\n",
    "u_train_df = train_df.loc[train_df['labeled'] == 0]\n",
    "pprint('LABELED has {} data'.format(l_train_df.shape[0]))\n",
    "pprint('UNLABELED has {} data'.format(u_train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Embedding with doc2vec===================='\n",
      "'DOC2VEC: Labeled training documents embedded into (1123, 300) dimensions'\n",
      "'DOC2VEC: Unlabeled training documents embedded into (10191, 300) dimensions'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embed all documents with doc2vec\n",
    "pprint('=' * 20 + 'Embedding with doc2vec' + '=' * 20)\n",
    "model = Doc2Vec.load(config['embed']['doc2vec_path'])\n",
    "l_train_doc2vec = np.array([model.infer_vector(doc.strip().split()) for doc in l_train_df['doc'].values])\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_doc2vec = np.array([model.infer_vector(doc.strip().split()) for doc in u_train_df['doc'].values])\n",
    "test_doc2vec = np.array([model.infer_vector(doc.strip().split()) for doc in test_df['doc'].values])\n",
    "pprint('DOC2VEC: Labeled training documents embedded into {} dimensions'.format(l_train_doc2vec.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('DOC2VEC: Unlabeled training documents embedded into {} dimensions'.format(u_train_doc2vec.shape))\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Embedding with tfidf===================='\n",
      "'TFIDF: Labeled training documents embedded into (1123, 10000) dimensions'\n",
      "'TFIDF: Unlabeled training documents embedded into (10191, 10000) dimensions'\n"
     ]
    }
   ],
   "source": [
    "#### embed all documents with tfidf\n",
    "pprint('=' * 20 + 'Embedding with tfidf' + '=' * 20)\n",
    "ngram_range = (1, 3)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{3,}',\n",
    "    ngram_range=ngram_range,\n",
    "    dtype=np.float32,\n",
    "    norm='l2',\n",
    "    min_df=3,\n",
    "    max_df=.9\n",
    "    )\n",
    "vectorizer.fit_transform(train_df['doc'])  # fit on all training documents, regardless of labeled or unlabeled\n",
    "\n",
    "l_train_tfidf_text = vectorizer.transform(l_train_df['doc']).toarray()\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_tfidf_text = vectorizer.transform(u_train_df['doc']).toarray()\n",
    "test_tfidf_text = vectorizer.transform(test_df['doc']).toarray()\n",
    "\n",
    "pprint('TFIDF: Labeled training documents embedded into {} dimensions'.format(l_train_tfidf_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('TFIDF: Unlabeled training documents embedded into {} dimensions'.format(u_train_tfidf_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================USE===================='\n",
      "'USE: Labeled training documents embedded into (1123, 512) dimensions'\n",
      "'USE: Unlabeled training documents embedded into (10191, 512) dimensions'\n"
     ]
    }
   ],
   "source": [
    "#### embed all documents with USE\n",
    "pprint('=' * 20 + 'USE' + '=' * 20)\n",
    "\n",
    "l_train_use_text = USE_EMBED(l_train_df['doc']).numpy()\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_use_text = USE_EMBED(u_train_df['doc']).numpy()\n",
    "test_use_text = USE_EMBED(test_df['doc']).numpy()\n",
    "#end with\n",
    "\n",
    "pprint('USE: Labeled training documents embedded into {} dimensions'.format(l_train_use_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('USE: Unlabeled training documents embedded into {} dimensions'.format(u_train_use_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================BERT===================='\n",
      "'Converting to BERT....'\n",
      "tf.Tensor([1123   16], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#### embed all documents with BERT\n",
    "tf.keras.backend.set_floatx('float16')\n",
    "pprint('=' * 20 + 'BERT' + '=' * 20)\n",
    "l_train_pooledbert_text, l_train_seqbert_text = get_BERT(l_train_df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Converting to BERT....'\n",
      "tf.Tensor([10191    16], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"): # OOR error due to lack of memory resource, change to CPU compute\n",
    "    if u_train_df.shape[0] > 0:\n",
    "        u_train_pooledbert_text, u_train_seqbert_text = get_BERT(u_train_df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Converting to BERT....'\n",
      "tf.Tensor([7532   16], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    test_pooledbert_text, test_seqbert_text = get_BERT(test_df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_train_pooledbert_text = l_train_pooledbert_text.numpy()\n",
    "l_train_seqbert_text = l_train_seqbert_text.numpy()\n",
    "u_train_pooledbert_text = u_train_pooledbert_text.numpy()\n",
    "u_train_seqbert_text = u_train_seqbert_text.numpy()\n",
    "test_pooledbert_text = test_pooledbert_text.numpy()\n",
    "test_seqbert_text = test_seqbert_text.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'tensorflow._api.v2.config.threading',\n",
       " '__doc__': 'Public API for tf.config.threading namespace.\\n',\n",
       " '__package__': 'tensorflow._api.v2.config.threading',\n",
       " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x273da51b220>,\n",
       " '__spec__': ModuleSpec(name='tensorflow._api.v2.config.threading', loader=<_frozen_importlib_external.SourceFileLoader object at 0x00000273DA51B220>, origin='c:\\\\users\\\\user\\\\appdata\\\\local\\\\programs\\\\python\\\\python38\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\config\\\\threading\\\\__init__.py', submodule_search_locations=['c:\\\\users\\\\user\\\\appdata\\\\local\\\\programs\\\\python\\\\python38\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\config\\\\threading']),\n",
       " '__path__': ['c:\\\\users\\\\user\\\\appdata\\\\local\\\\programs\\\\python\\\\python38\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\config\\\\threading'],\n",
       " '__file__': 'c:\\\\users\\\\user\\\\appdata\\\\local\\\\programs\\\\python\\\\python38\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\config\\\\threading\\\\__init__.py',\n",
       " '__cached__': 'c:\\\\users\\\\user\\\\appdata\\\\local\\\\programs\\\\python\\\\python38\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\config\\\\threading\\\\__pycache__\\\\__init__.cpython-38.pyc',\n",
       " '__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __import__>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x0000027381E47430>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'Exception': Exception,\n",
       "  'TypeError': TypeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'SystemExit': SystemExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'ImportError': ImportError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'OSError': OSError,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'WindowsError': OSError,\n",
       "  'EOFError': EOFError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'NameError': NameError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'TabError': TabError,\n",
       "  'LookupError': LookupError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ValueError': ValueError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'SystemError': SystemError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'BufferError': BufferError,\n",
       "  'Warning': Warning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2020 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': Type license() to see the full license text,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       "  '__pybind11_internals_v3_msvc__': <capsule object NULL at 0x00000273C2489930>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x0000027381E26880>>},\n",
       " '_sys': <module 'sys' (built-in)>,\n",
       " 'get_inter_op_parallelism_threads': <function tensorflow.python.framework.config.get_inter_op_parallelism_threads()>,\n",
       " 'get_intra_op_parallelism_threads': <function tensorflow.python.framework.config.get_intra_op_parallelism_threads()>,\n",
       " 'set_inter_op_parallelism_threads': <function tensorflow.python.framework.config.set_inter_op_parallelism_threads(num_threads)>,\n",
       " 'set_intra_op_parallelism_threads': <function tensorflow.python.framework.config.set_intra_op_parallelism_threads(num_threads)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.config.threading' has no attribute 'intra_op_parallelism_threads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4e5823dfe6d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintra_op_parallelism_threads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.config.threading' has no attribute 'intra_op_parallelism_threads'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================ELMO===================='\n",
      "'Converting to ELMO....'\n",
      "8619    Summer Sublet Wanted in DC NNTPPostingHost jhu...\n",
      "8766    Re ASTROS FOR REAL I AGREE LUMBERJACK except t...\n",
      "9855    Re Organized Lobbying for Cryptography I think...\n",
      "2037       Re Vandalizing the sky most of message deleted\n",
      "8538    Re int15h for joysticks is slow The joystick r...\n",
      "                              ...                        \n",
      "4372                 Re extraordinary footpeg engineering\n",
      "6274    Solution Why do I need xrdb m when Xdefaults u...\n",
      "4152      Re Need a good concave convex polygon algorithm\n",
      "1055    Re Nikon FM2 and lens forsale FM2 has been sol...\n",
      "6915    Re Looking for Electronics Dept Info in Austra...\n",
      "Name: doc, Length: 1123, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#### embed all documents with ELMO\n",
    "with tf.device('/CPU:0'):\n",
    "    pprint('=' * 20 + 'ELMO' + '=' * 20)\n",
    "    l_train_pooledelmo_text, l_train_seqelmo_text = get_ELMO(l_train_df['doc'])\n",
    "    pprint('training data finished.')\n",
    "    if u_train_df.shape[0] > 0:\n",
    "        u_train_pooledelmo_text, u_train_seqelmo_text = get_ELMO(u_train_df['doc'])\n",
    "    test_pooledelmo_text, test_seqelmo_text = get_ELMO(test_df['doc'], session)\n",
    "#end with\n",
    "\n",
    "pprint('POOLEDELMO: Labeled training documents embedded into {} dimensions'.format(l_train_pooledelmo_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('POOLEDELMO: Unlabeled training documents embedded into {} dimensions'.format(u_train_pooledelmo_text.shape))\n",
    "\n",
    "pprint('SEQELMO: Labeled training documents embedded into {} dimensions'.format(l_train_seqelmo_text.shape))\n",
    "if u_train_df.shape[0] > 0:\n",
    "    pprint('SEQELMO: Unlabeled training documents embedded into {} dimensions'.format(u_train_seqelmo_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Binarized Classes: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\\n\"\n",
      " \" 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\\n\"\n",
      " \" 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\\n\"\n",
      " \" 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\\n\"\n",
      " \" 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\\n\"\n",
      " \" 'talk.politics.misc' 'talk.religion.misc']\")\n",
      "(\"Encoded Classes: ['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\\n\"\n",
      " \" 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\\n\"\n",
      " \" 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\\n\"\n",
      " \" 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\\n\"\n",
      " \" 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\\n\"\n",
      " \" 'talk.politics.misc' 'talk.religion.misc']\")\n"
     ]
    }
   ],
   "source": [
    "#### binarize train target\n",
    "lb = LabelBinarizer().fit(train_df['cat'].values)\n",
    "l_train_cat_bin = lb.transform(l_train_df['cat'].values)\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_cat_bin = lb.transform(u_train_df['cat'].values)\n",
    "pprint('Binarized Classes: {}'.format(lb.classes_))\n",
    "#### binarize test target\n",
    "test_cat_bin = lb.transform(test_df['cat'].values)\n",
    "\n",
    "#### encode train target\n",
    "le = LabelEncoder().fit(train_df['cat'].values)\n",
    "l_train_cat_en = le.transform(l_train_df['cat'].values)\n",
    "if u_train_df.shape[0] > 0:\n",
    "    u_train_cat_en = le.transform(u_train_df['cat'].values)\n",
    "pprint('Encoded Classes: {}'.format(le.classes_))\n",
    "#### encode test target\n",
    "test_cat_en = le.transform(test_df['cat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save all embedded documents\n",
    "#### save labeled train data to output path\n",
    "if config['labeled_train_out']:\n",
    "    l_train_data = [\n",
    "        dict(\n",
    "            # fasttext=l_train_fasttext_text[i],\n",
    "            # pooledbiobert=l_train_pooledbiobert_text[i],\n",
    "            # seqbiobert=l_train_seqbiobert_text[i],\n",
    "            tfidf=l_train_tfidf_text[i],\n",
    "            doc2vec=l_train_doc2vec[i],\n",
    "            use=l_train_use_text[i],\n",
    "            # pooledbert=l_train_pooledbert_text[i],\n",
    "            # seqbert=l_train_seqbert_text[i],\n",
    "            # pooledelmo=l_train_pooledelmo_text[i],\n",
    "            # seqelmo=l_train_seqelmo_text[i],\n",
    "            cat_bin=label,\n",
    "            cat_en=l_train_cat_en[i],\n",
    "            id=l_train_df['id'].values[i])\n",
    "        for i, label in enumerate(l_train_cat_bin)]\n",
    "    joblib.dump(\n",
    "        l_train_data,\n",
    "        config['labeled_train_out'],\n",
    "        compress=3)\n",
    "# end if\n",
    "\n",
    "#### save unlabeled train data to output path\n",
    "if config['unlabeled_train_out'] and u_train_df.shape[0] > 0:\n",
    "    u_train_data = [\n",
    "        dict(\n",
    "            # fasttext=u_train_fasttext_text[i],\n",
    "            # pooledbiobert=u_train_pooledbiobert_text[i],\n",
    "            # seqbiobert=u_train_seqbiobert_text[i],\n",
    "            tfidf=u_train_tfidf_text[i],\n",
    "            doc2vec=u_train_doc2vec[i],\n",
    "            use=u_train_use_text[i],\n",
    "            # pooledbert=u_train_pooledbert_text[i],\n",
    "            # seqbert=u_train_seqbert_text[i],\n",
    "            # pooledelmo=u_train_pooledelmo_text[i],\n",
    "            # seqelmo=u_train_seqelmo_text[i],\n",
    "            cat_bin=label,\n",
    "            cat_en=u_train_cat_en[i],\n",
    "            id=u_train_df['id'].values[i])\n",
    "        for i, label in enumerate(u_train_cat_bin)]\n",
    "    joblib.dump(\n",
    "        u_train_data,\n",
    "        config['unlabeled_train_out'],\n",
    "        compress=3)\n",
    "# end if\n",
    "\n",
    "if config['test_out']:\n",
    "    test_data = [\n",
    "        dict(\n",
    "            # fasttext=test_fasttext_text[i],\n",
    "            # pooledbiobert=test_pooledbiobert_text[i],\n",
    "            # seqbiobert=test_seqbiobert_text[i],\n",
    "            tfidf=test_tfidf_text[i],\n",
    "            doc2vec=test_doc2vec[i],\n",
    "            use=test_use_text[i],\n",
    "            # pooledbert=test_pooledbert_text[i],\n",
    "            # seqbert=test_seqbert_text[i],\n",
    "            # pooledelmo=test_pooledelmo_text[i],\n",
    "            # seqelmo=test_seqelmo_text[i],\n",
    "            cat_bin=label,\n",
    "            cat_en=test_cat_en[i],\n",
    "            id=test_df['id'].values[i])\n",
    "        for i, label in enumerate(test_cat_bin)]\n",
    "    joblib.dump(\n",
    "        test_data,\n",
    "        config['test_out'],\n",
    "        compress=3)\n",
    "# end if\n",
    "\n",
    "#### save binarizer to output path\n",
    "if config['encoder_out']:\n",
    "    joblib.dump(\n",
    "        le,\n",
    "        config['encoder_out'],\n",
    "        compress=3)\n",
    "\n",
    "#### save encoder to output path\n",
    "if config['binarizer_out']:\n",
    "    joblib.dump(\n",
    "        lb,\n",
    "        config['binarizer_out'],\n",
    "        compress=3)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'doc2vec': array([ 4.33510765e-02, -1.60855625e-03, -2.95351651e-02,  2.54913941e-02,\n",
       "        -2.94385068e-02, -6.36041351e-03,  1.13445275e-01, -4.47121933e-02,\n",
       "         5.95487328e-03,  6.89874822e-03, -8.49912167e-02, -3.36255543e-02,\n",
       "        -2.63531599e-02, -4.93617095e-02,  3.19814309e-02,  9.58273262e-02,\n",
       "        -9.50160325e-02, -8.67595598e-02, -1.33213950e-02,  2.25978233e-02,\n",
       "         5.50076254e-02, -1.65605601e-02, -1.08385878e-03, -5.97499572e-02,\n",
       "         7.78176486e-02, -1.32156452e-02,  1.84632989e-03, -5.75479455e-02,\n",
       "        -8.40366930e-02, -8.87737125e-02, -6.69519156e-02,  4.55964245e-02,\n",
       "        -1.97679792e-02,  5.76041732e-03,  4.89181578e-02, -2.70229392e-02,\n",
       "         2.65085045e-02,  6.93085091e-03,  4.70224433e-02, -2.02025715e-02,\n",
       "         6.39714580e-03,  3.41412276e-02,  3.14988196e-02, -1.61610674e-02,\n",
       "        -1.48716662e-02, -1.79685019e-02,  3.02185323e-02,  2.54172347e-02,\n",
       "         8.52239057e-02, -2.50934362e-02,  1.87393557e-02, -3.51713262e-02,\n",
       "         3.62170748e-02, -3.24031003e-02, -3.35424766e-02, -4.54575159e-02,\n",
       "         3.46029662e-02, -2.56613661e-02, -6.41148314e-02, -3.43776904e-02,\n",
       "         1.22743836e-02,  1.37549704e-02, -4.20432389e-02,  3.66891548e-03,\n",
       "         2.29393952e-02, -3.65497619e-02, -1.07022412e-02, -9.39066410e-02,\n",
       "         4.47359793e-02,  2.41091084e-02,  7.43003711e-02, -2.41059344e-04,\n",
       "        -1.14318551e-02,  5.58994934e-02, -5.75030483e-02, -1.78525560e-02,\n",
       "        -3.89187261e-02,  5.72703518e-02,  2.85156965e-02, -7.35084563e-02,\n",
       "         4.48258482e-02,  5.11667021e-02, -3.88206616e-02,  2.20587514e-02,\n",
       "        -5.84872328e-02, -1.40044428e-02, -6.34153932e-02, -3.91505547e-02,\n",
       "         2.95782052e-02,  4.83388193e-02, -1.45546738e-02, -1.24098495e-01,\n",
       "         5.01885898e-02, -7.57105947e-02, -1.19453579e-01,  2.42470670e-02,\n",
       "         5.23596816e-02, -4.30274867e-02, -1.74377207e-02, -7.14437515e-02,\n",
       "        -9.93076414e-02, -5.05884038e-03, -2.96916105e-02,  3.75532247e-02,\n",
       "         5.46187256e-03,  3.42524191e-03, -9.99510475e-03,  8.37616995e-02,\n",
       "         1.66311730e-02, -4.84471731e-02,  2.89828014e-02, -2.96732597e-02,\n",
       "        -6.93147108e-02,  4.56384458e-02, -8.83423910e-02, -2.09373347e-02,\n",
       "         5.35459518e-02, -1.20315896e-02, -5.07249730e-03,  3.84158343e-02,\n",
       "        -5.99975847e-02, -3.49739417e-02,  1.42273670e-02,  1.01433642e-01,\n",
       "        -1.07339941e-01,  7.57267103e-02, -2.07861345e-02, -1.22445948e-01,\n",
       "         9.00011584e-02,  4.94319573e-02,  1.70015264e-02, -1.07646491e-02,\n",
       "        -9.17563913e-04, -7.01457709e-02, -2.71477252e-02, -4.39927392e-02,\n",
       "        -2.71265246e-02, -3.90668698e-02,  1.35493139e-02, -1.80130247e-02,\n",
       "         1.26162674e-02, -5.79928868e-02,  1.59791224e-02, -1.94821460e-03,\n",
       "         2.35652700e-02,  7.60300532e-02,  9.81033314e-03, -6.46605715e-02,\n",
       "        -3.60055943e-04,  4.72241044e-02,  7.48745427e-02, -1.14657748e-02,\n",
       "         9.27491765e-03, -8.24840516e-02,  2.89341528e-02, -7.78708234e-02,\n",
       "        -1.17741646e-02, -5.63660823e-02,  4.00259644e-02, -6.12262711e-02,\n",
       "        -7.70701887e-03,  3.75667773e-02, -1.87950861e-02, -3.49855125e-02,\n",
       "        -3.61772277e-03,  5.70649914e-02,  1.19466064e-02,  4.40719090e-02,\n",
       "         6.16041645e-02, -2.67169103e-02,  2.47788969e-02,  3.13803018e-03,\n",
       "         4.92789457e-03, -4.27951254e-02,  4.79424372e-02, -7.15155229e-02,\n",
       "        -6.09915294e-02,  2.49077063e-02, -4.96621095e-02,  8.58226120e-02,\n",
       "         1.02642654e-02,  1.39668733e-01, -4.03035022e-02, -4.57788780e-02,\n",
       "         2.40760874e-02,  2.83215027e-02, -4.61454615e-02,  7.62239248e-02,\n",
       "        -9.10355747e-02,  3.72163057e-02,  6.99379817e-02, -1.36496156e-01,\n",
       "         4.35486659e-02,  7.37735778e-02, -1.66799054e-02, -5.54762147e-02,\n",
       "         1.06766529e-01, -8.36932808e-02, -7.75722936e-02,  6.39736233e-03,\n",
       "         5.71283959e-02,  1.10321390e-02,  1.76937003e-02, -3.39289643e-02,\n",
       "        -3.23396884e-02, -1.09443925e-02, -4.32286039e-03, -2.58702114e-02,\n",
       "        -1.84642076e-02, -2.83941943e-02,  1.28243519e-02,  5.76112233e-02,\n",
       "        -2.69436426e-02, -5.84812798e-02,  1.71786305e-02, -3.81674953e-02,\n",
       "        -2.62510478e-02, -2.33992804e-02, -5.47830528e-03, -1.52215296e-02,\n",
       "         8.18592682e-02,  9.15507302e-02, -5.45442943e-03,  9.66314878e-03,\n",
       "        -9.64287296e-02, -2.44478434e-02, -1.28575906e-01,  2.18614005e-02,\n",
       "         7.06775719e-03,  3.79337184e-02,  6.17129775e-03, -2.57185381e-02,\n",
       "         6.48038536e-02,  3.12036835e-02,  5.64582013e-02, -5.15886694e-02,\n",
       "         3.53144705e-02,  1.19109493e-04,  5.59741296e-02, -2.62263622e-02,\n",
       "        -6.04228228e-02, -6.17754869e-02, -3.10192872e-02,  3.60132307e-02,\n",
       "        -4.04866934e-02, -7.62124807e-02,  1.08603433e-01, -2.75721308e-02,\n",
       "         1.95923280e-02,  1.95991714e-02, -8.25530104e-03, -9.30310693e-03,\n",
       "         3.96284871e-02,  7.41522387e-03, -9.69671011e-02,  4.66527492e-02,\n",
       "         9.05009434e-02, -4.16583121e-02, -6.27916364e-04, -2.41483040e-02,\n",
       "         2.94426549e-02, -3.78499506e-03, -4.98676598e-02, -7.03122392e-02,\n",
       "         1.92288943e-02, -1.07950959e-02,  2.34197415e-02, -3.32102962e-02,\n",
       "         2.58570872e-02, -1.45359831e-02,  1.37316706e-02,  8.71559232e-02,\n",
       "         2.14401986e-02,  5.92355430e-02,  4.34511825e-02,  8.56653694e-03,\n",
       "         5.22258319e-02, -3.10131479e-02,  5.26814954e-03, -8.04863870e-03,\n",
       "        -6.24901019e-02,  9.71470550e-02, -3.42846401e-02,  6.45767152e-02,\n",
       "         8.33670571e-02,  4.06998992e-02, -1.05049387e-02,  4.69697843e-04,\n",
       "         1.55853489e-02, -1.15255646e-01, -1.23300543e-02,  6.72078431e-02,\n",
       "        -5.45762740e-02,  4.59955335e-02, -4.72932085e-02, -9.38354284e-02,\n",
       "        -5.16594611e-02,  6.22267043e-03, -5.79664260e-02,  4.12334725e-02],\n",
       "       dtype=float32),\n",
       " 'use': array([ 3.46717946e-02, -7.89296106e-02, -7.13744015e-02,  4.37052548e-03,\n",
       "         4.53473181e-02,  2.92269955e-03,  5.30480780e-02, -2.81734634e-02,\n",
       "         1.88459698e-02,  4.54203784e-02, -8.27709436e-02, -6.36412278e-02,\n",
       "        -6.78922981e-02, -3.49506140e-02,  4.18686904e-02, -7.13638514e-02,\n",
       "        -1.34167308e-02, -2.58751325e-02, -2.22321562e-02,  4.74407710e-02,\n",
       "        -2.67988183e-02,  2.95384936e-02,  9.01199728e-02, -1.44463582e-02,\n",
       "         2.17008013e-02, -1.33776413e-02, -7.27023855e-02, -4.70263138e-02,\n",
       "        -3.14377844e-02, -4.30049710e-02,  2.17204429e-02,  3.30197848e-02,\n",
       "        -3.51574533e-02, -3.25053558e-03, -7.19449893e-02,  5.67863695e-04,\n",
       "        -1.92051027e-02,  5.55094481e-02,  1.85723752e-02,  2.09861752e-02,\n",
       "         1.58615615e-02, -4.01720293e-02,  4.11042757e-02, -3.85175757e-02,\n",
       "        -4.09887964e-03,  1.39718065e-02, -2.22489294e-02,  3.75097943e-03,\n",
       "         5.26745282e-02, -1.89918559e-02,  9.26919281e-02, -8.67774040e-02,\n",
       "         9.14706034e-04, -3.63037363e-02,  9.29870456e-03,  3.80049013e-02,\n",
       "        -2.28995476e-02, -2.06704494e-02, -1.63995083e-02,  6.05842099e-02,\n",
       "         4.68479581e-02, -3.85923311e-02, -7.12425634e-02,  6.13292772e-03,\n",
       "         2.85300203e-02,  6.66413754e-02,  2.20585391e-02, -3.78649831e-02,\n",
       "         2.83174030e-02,  7.94418305e-02,  8.61306302e-03, -1.04043353e-02,\n",
       "        -3.54986489e-02,  6.96142763e-02,  5.71560301e-02,  3.09529044e-02,\n",
       "        -3.93292904e-02,  1.48381423e-02,  6.91174939e-02,  5.56117669e-02,\n",
       "         3.27367745e-02,  2.66738907e-02,  1.02749246e-03, -2.82115061e-02,\n",
       "        -7.19373580e-03, -1.00247432e-02, -6.72158152e-02, -2.14825682e-02,\n",
       "         2.25710180e-02,  5.18641844e-02, -4.77092043e-02,  3.22100371e-02,\n",
       "        -6.61419705e-02, -7.12942379e-03,  4.23434339e-02,  3.53594031e-03,\n",
       "         5.99792153e-02,  6.42466396e-02, -7.43579492e-02, -1.87599566e-03,\n",
       "        -4.66977768e-02,  6.46970421e-03,  1.64824560e-05,  2.88610850e-02,\n",
       "        -4.53077145e-02,  5.89270368e-02, -4.66642119e-02,  4.50929254e-02,\n",
       "        -5.23163527e-02,  2.44955961e-02, -8.53606910e-02, -7.36639276e-02,\n",
       "        -1.39788492e-02,  5.26922718e-02,  4.65422943e-02,  9.92688164e-03,\n",
       "         4.37301025e-02,  2.01400090e-02,  3.93857360e-02,  6.60896860e-03,\n",
       "         5.12545183e-02,  4.89254259e-02, -2.08491217e-02, -4.13477868e-02,\n",
       "         2.57266201e-02,  3.70662543e-04,  6.44454826e-03, -3.02723907e-02,\n",
       "         2.11103223e-02, -5.45120798e-02,  7.95725826e-03, -5.82032688e-02,\n",
       "        -6.67721918e-03,  1.87318271e-03,  5.94035797e-02, -7.72829056e-02,\n",
       "        -2.93130670e-02,  6.29193801e-03, -2.54015326e-02, -6.36385903e-02,\n",
       "         2.77321339e-02, -2.42626201e-02,  1.28698559e-03, -5.58019755e-03,\n",
       "         4.25047167e-02, -4.07932065e-02, -6.24833815e-02,  6.28243461e-02,\n",
       "        -8.05263445e-02,  3.91951054e-02,  9.02752504e-02,  3.85562591e-02,\n",
       "         3.82167958e-02,  8.31547938e-03, -6.87545314e-02, -2.95924824e-02,\n",
       "         1.97864175e-02, -9.13686678e-02, -2.15748828e-02, -8.18149745e-02,\n",
       "        -7.79685602e-02, -1.04350075e-02, -4.64873277e-02, -2.44815950e-03,\n",
       "         5.09310998e-02, -3.12227271e-02, -1.42724691e-02, -2.51628105e-02,\n",
       "         3.98360789e-02,  4.01074402e-02, -1.47958035e-02, -7.40687400e-02,\n",
       "        -5.81651041e-03, -6.63966015e-02,  7.15459585e-02, -3.57038006e-02,\n",
       "         1.72896683e-02, -1.07155007e-03,  3.63569595e-02,  4.88078706e-02,\n",
       "         9.14850086e-03, -5.36946617e-02,  5.53385429e-02,  5.01221567e-02,\n",
       "         4.61794287e-02,  5.13070542e-03,  4.73151468e-02,  2.37994958e-02,\n",
       "         1.35545954e-02, -4.58057337e-02, -4.54216264e-02, -3.17110717e-02,\n",
       "         3.68428864e-02,  4.26927470e-02,  7.07347691e-02,  1.61541607e-02,\n",
       "         1.38034523e-02, -3.14350352e-02, -2.53116116e-02,  1.31672863e-02,\n",
       "        -2.95674540e-02,  3.38495453e-03,  7.02148536e-03,  4.90834285e-03,\n",
       "        -4.06768844e-02,  6.12320565e-03, -1.20854434e-02,  1.66517608e-02,\n",
       "        -3.90027389e-02, -3.42064239e-02, -7.04261065e-02, -5.65012470e-02,\n",
       "         2.45986599e-02, -6.61620274e-02, -5.43762185e-02,  8.49353895e-02,\n",
       "        -1.14303995e-02,  6.14104569e-02,  2.72908546e-02,  6.15922734e-02,\n",
       "        -3.58123966e-02, -1.80249400e-02,  2.39048414e-02, -4.61298265e-02,\n",
       "         2.37226710e-02,  4.40946147e-02,  4.62987684e-02, -5.28367385e-02,\n",
       "        -2.68951878e-02, -4.89468090e-02,  4.34132032e-02, -5.48319817e-02,\n",
       "         1.27669610e-02,  9.57401991e-02,  6.36724895e-03, -1.55329406e-02,\n",
       "         4.61478680e-02, -2.03123167e-02, -1.48255778e-02,  1.49294818e-02,\n",
       "        -2.69834325e-02, -2.79230904e-02,  4.20820201e-03,  4.99084294e-02,\n",
       "         6.73070326e-02,  3.50901298e-02,  8.07256810e-03,  3.73982936e-02,\n",
       "        -4.07137349e-03,  2.27497332e-02,  6.48339838e-02,  7.40023050e-03,\n",
       "         7.46313576e-03, -7.36680329e-02, -3.66711281e-02,  1.49778062e-02,\n",
       "         6.02148734e-02, -3.88078503e-02, -6.76774755e-02, -5.44585511e-02,\n",
       "         4.02399972e-02, -1.69201214e-02, -1.33487722e-02,  1.77911986e-02,\n",
       "         6.83193803e-02,  1.38927065e-02,  4.57919911e-02,  3.09173409e-02,\n",
       "         2.54537836e-02, -3.38158458e-02, -6.62241951e-02,  4.71100919e-02,\n",
       "        -1.80562213e-02,  2.59294380e-02,  4.16386127e-02, -7.44368061e-02,\n",
       "         1.24610122e-02,  6.79322407e-02,  6.00269474e-02, -1.70633458e-02,\n",
       "        -1.10832239e-02, -2.69218124e-02,  3.23485956e-02, -1.45579968e-02,\n",
       "         3.47120352e-02, -3.27764079e-02, -4.06246483e-02,  2.95972303e-02,\n",
       "        -5.94010167e-02,  4.98263463e-02, -2.54642144e-02,  6.58412427e-02,\n",
       "        -4.08281051e-02,  4.65920642e-02,  3.43073346e-02, -2.79789604e-02,\n",
       "         5.45626739e-03,  5.84536269e-02, -8.64924490e-02, -9.20408294e-02,\n",
       "         1.20503567e-02,  5.59779219e-02,  1.09976192e-03,  1.12384362e-02,\n",
       "        -5.41366749e-02, -6.65641651e-02, -5.09153344e-02, -7.51813641e-03,\n",
       "        -6.93064034e-02,  4.21483405e-02,  4.92181964e-02,  6.96588755e-02,\n",
       "        -2.20710672e-02,  6.13249764e-02, -1.45179406e-02, -1.91031694e-02,\n",
       "         5.10825589e-02,  7.43280575e-02, -3.99601795e-02,  7.75753036e-02,\n",
       "         2.98776552e-02,  1.97040737e-02, -1.68487877e-02,  5.75984418e-02,\n",
       "         4.95568886e-02,  4.31732833e-02, -7.24932998e-02,  3.68203819e-02,\n",
       "         5.38652809e-03, -1.77202967e-03,  5.95917329e-02,  2.14564353e-02,\n",
       "         3.99460010e-02, -4.92495075e-02, -2.16250047e-02, -4.64547053e-02,\n",
       "        -1.86771024e-02,  3.64148095e-02,  5.03161624e-02,  1.53965375e-03,\n",
       "         9.77164432e-02, -3.03928871e-02, -5.86235570e-03, -2.84547620e-02,\n",
       "         1.86179150e-02, -1.37738986e-02, -2.87032109e-02, -2.47171876e-04,\n",
       "         3.89842130e-02,  1.64681077e-02,  1.28864786e-02,  3.06907110e-02,\n",
       "        -3.34067680e-02,  4.10260856e-02, -7.15390891e-02, -5.42590208e-02,\n",
       "        -8.86559784e-02,  5.57398945e-02,  4.53180149e-02,  4.22073156e-02,\n",
       "         3.50125097e-02, -4.32184013e-03,  8.18451568e-02, -1.10512413e-02,\n",
       "         3.18712555e-02,  3.88347134e-02,  1.88362356e-02, -3.85839343e-02,\n",
       "        -4.94245738e-02, -6.87607378e-02,  5.09194881e-02, -4.93075661e-02,\n",
       "        -4.83738892e-02,  3.01953740e-02,  6.85204566e-02, -6.50569871e-02,\n",
       "         1.51113821e-02, -5.03773876e-02, -7.80169889e-02, -3.26546617e-02,\n",
       "         1.19769247e-02, -6.83233812e-02,  1.96188800e-02,  2.66852416e-02,\n",
       "        -4.23212424e-02, -3.79243493e-02, -3.62018757e-02,  4.08557355e-02,\n",
       "        -8.39615148e-03,  1.19366888e-02,  6.67925412e-03,  8.76323879e-02,\n",
       "         1.70687083e-02,  5.42550683e-02,  6.27030730e-02,  7.43380487e-02,\n",
       "        -7.97145665e-02,  7.94388354e-03,  5.57125919e-02,  2.47425698e-02,\n",
       "        -8.63583386e-03,  5.70373610e-02, -3.19524892e-02,  3.09174117e-02,\n",
       "         5.75656593e-02, -2.75200363e-02,  8.87566507e-02,  6.64237812e-02,\n",
       "        -2.01260261e-02,  3.92711200e-02,  3.04811429e-02, -1.74361859e-02,\n",
       "         6.77568689e-02, -5.97281680e-02, -7.43596163e-03, -1.52602848e-02,\n",
       "         5.66281518e-03, -2.21895869e-03,  2.17699092e-02,  1.02640893e-02,\n",
       "        -5.47788702e-02,  4.00753431e-02,  3.76905799e-02, -5.83611242e-02,\n",
       "         5.28726317e-02,  4.04716423e-03,  2.33182181e-02, -4.82718162e-02,\n",
       "         6.17722683e-02, -3.18629444e-02, -3.57153267e-02,  4.25514393e-02,\n",
       "        -4.90513518e-02,  5.83980307e-02, -1.91320181e-02, -4.73254025e-02,\n",
       "        -4.54264283e-02, -4.30534268e-03, -2.94692814e-02, -3.23020155e-04,\n",
       "         8.59702602e-02, -4.26589586e-02,  6.50291145e-02, -8.03599954e-02,\n",
       "        -5.38294353e-02, -1.09198866e-02, -1.14051141e-02,  6.06494211e-02,\n",
       "         1.81010105e-02, -2.56902594e-02, -4.41248193e-02,  3.75790596e-02,\n",
       "         5.09007946e-02,  4.66048755e-02,  4.98007387e-02, -6.56271726e-02,\n",
       "        -5.95262088e-02, -3.50762084e-02, -4.95928898e-02,  4.46632355e-02,\n",
       "         4.65092435e-02, -4.58293483e-02, -6.16092868e-02, -6.54319162e-03,\n",
       "        -3.12098619e-02,  5.24157379e-03,  4.80774567e-02,  4.21323366e-02,\n",
       "        -4.47463840e-02,  1.80416536e-02, -3.00620704e-05, -7.61355609e-02,\n",
       "         4.41552140e-02,  4.06529009e-02, -2.22624168e-02, -5.25703914e-02,\n",
       "        -6.19170256e-02, -6.72203600e-02,  9.46817398e-02,  7.40456730e-02,\n",
       "         9.16614234e-02,  1.77426804e-02,  7.86859617e-02,  6.65371073e-04,\n",
       "        -9.00148880e-03, -2.38811299e-02, -9.45992954e-03,  2.55517475e-03,\n",
       "         4.69342768e-02,  6.24369783e-03, -9.83889494e-03, -2.78644934e-02,\n",
       "        -5.72953187e-02,  1.75317451e-02,  2.08900850e-02, -6.83151651e-03,\n",
       "         3.05940174e-02,  5.07041141e-02,  5.49348705e-02, -5.64708747e-02,\n",
       "         2.54759993e-02, -4.64125052e-02, -7.36047402e-02, -6.50391122e-03,\n",
       "         1.44363390e-02,  7.09342808e-02,  5.36752939e-02, -2.44495589e-02,\n",
       "        -2.97617894e-02,  5.59381694e-02, -5.37630133e-02, -2.15614960e-03],\n",
       "       dtype=float32),\n",
       " 'cat_bin': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'cat_en': 9,\n",
       " 'id': 'C:\\\\Users\\\\User\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-test\\\\rec.sport.baseball\\\\104855'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[20]['doc2vec'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
