{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import joblib\n",
    "import random\n",
    "import xgboost\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GRU\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import Input\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================Configs===================='\n"
     ]
    }
   ],
   "source": [
    "# load constants and config\n",
    "config_path = '../config/20news.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# end with\n",
    "pprint('=' * 20 + 'Configs' + '=' * 20)\n",
    "\n",
    "\n",
    "LB, L, T, TEXT_EMBEDDING_MATRIX = None, None, None, None\n",
    "LR = 0.001 # learning rate\n",
    "random.seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "tf.random.set_seed(config['seed'])\n",
    "LB = joblib.load(config['binarizer_out'])\n",
    "LE = joblib.load(config['encoder_out'])\n",
    "L = joblib.load(config['labeled_train_out'])\n",
    "T = joblib.load(config['test_out'])\n",
    "random.shuffle(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    text_input_shape,\n",
    "    output_shape,\n",
    "    dropout_rate=0,\n",
    "    kernel_regularizer=0,\n",
    "    activity_regularizer=0,\n",
    "    bias_regularizer=0,\n",
    "    **kwargs):\n",
    "\n",
    "    text_input = Input(text_input_shape, name='text_input')\n",
    "    \n",
    "    text = Dense(\n",
    "        512,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(kernel_regularizer),\n",
    "        bias_regularizer=regularizers.l2(bias_regularizer))(text_input)  # down size the learnt representation\n",
    "    # text = BatchNormalization()(text)\n",
    "    text = Dropout(dropout_rate)(text)\n",
    "    # x = Dense(\n",
    "    #     64,\n",
    "    #     activation='relu',\n",
    "    #     kernel_regularizer=regularizers.l2(kernel_regularizer),\n",
    "    #     bias_regularizer=regularizers.l2(bias_regularizer))(text)  # down size the learnt representation\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(dropout_rate)(x)\n",
    "    # x = Dense(\n",
    "    #     64,\n",
    "    #     activation='relu',\n",
    "    #     kernel_regularizer=regularizers.l2(kernel_regularizer),\n",
    "    #     bias_regularizer=regularizers.l2(bias_regularizer))(x)  # down size the learnt representation\n",
    "    # x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    output = Dense(output_shape, activation='softmax', name='output')(text)\n",
    "\n",
    "    model = Model(inputs=[text_input], outputs=[output])\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(LR, decay=1e-6),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_model(\n",
    "    text_input_shape,\n",
    "    output_shape,\n",
    "    dropout_rate=0,\n",
    "    kernel_regularizer=0,\n",
    "    activity_regularizer=0,\n",
    "    bias_regularizer=0,\n",
    "    **kwargs):\n",
    "\n",
    "    text_input = Input(text_input_shape, name='text_input')\n",
    "    text = Convolution1D(256, 3, activation=\"relu\")(text_input)\n",
    "    # text = MaxPooling1D()(text)\n",
    "    # text = Convolution1D(512, 3, activation=\"relu\")(text)\n",
    "    text = GlobalMaxPooling1D()(text)\n",
    "\n",
    "    # x = Dense(\n",
    "    #     64,\n",
    "    #     activation='relu',\n",
    "    #     kernel_regularizer=regularizers.l2(kernel_regularizer),\n",
    "    #     bias_regularizer=regularizers.l2(bias_regularizer))(text)  # down size the learnt representation\n",
    "    # # x = BatchNormalization()(x)\n",
    "    # x = Dropout(dropout_rate)(x)\n",
    "    # x = Dense(\n",
    "    #     64,\n",
    "    #     activation='relu',\n",
    "    #     kernel_regularizer=regularizers.l2(kernel_regularizer),\n",
    "    #     bias_regularizer=regularizers.l2(bias_regularizer))(x)  # down size the learnt representation\n",
    "    # # x = BatchNormalization()(x)\n",
    "    # x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    output = Dense(output_shape, activation='softmax', name='output')(text)\n",
    "\n",
    "    model = Model(inputs=[text_input], outputs=[output])\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(LR, decay=1e-6),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(rep):\n",
    "    print('='*20 + rep + 'svm' + '='*20, flush=True)\n",
    "    global LE, LB, U, L, U_prime, n, k, u, config\n",
    "    train_train = np.array([np.array(item[rep]) for item in L])\n",
    "    y_train = np.array([np.array(item['cat_en']) for item in L])\n",
    "\n",
    "    # Use L1 to train a classifier h1 that considers only the use representation of doc\n",
    "    h1 = LinearSVC(random_state=0, tol=1e-5)\n",
    "    h1.fit(train_train, y_train)\n",
    "\n",
    "    # define the third combined classifier from h1 and h2,\n",
    "    # and test the performance of h1 and h2 on test set\n",
    "    print('=' * 50 + 'Predicting on Test Set....' + '=' * 50, flush=True)\n",
    "\n",
    "    T_test = np.array([np.array(item[rep]) for item in T])\n",
    "    pprint(T[0]['pooledbert'].shape)\n",
    "    pprint(T[0]['seqbert'].shape)\n",
    "    pprint(T[0]['doc2vec'].shape)\n",
    "    h1_y_pred = h1.predict(T_test)\n",
    "    del T_test\n",
    "    gc.collect()\n",
    "\n",
    "    h1_y_pred = LE.inverse_transform(h1_y_pred)\n",
    "\n",
    "    y_true = np.array([item['cat_bin'] for item in T])\n",
    "    y_true = LB.inverse_transform(y_true)\n",
    "\n",
    "    print(accuracy_score(y_true, h1_y_pred), flush=True)\n",
    "\n",
    "    print(classification_report(y_true, h1_y_pred), flush=True)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(rep):\n",
    "    print('='*20 + rep + 'mlp' + '='*20, flush=True)\n",
    "    global LB, L, T, TEXT_EMBEDDING_MATRIX, config\n",
    "    T_test = np.array([np.array(item[rep]).flatten() for item in T])\n",
    "\n",
    "    train = np.array([np.array(item[rep]).flatten() for item in L])\n",
    "    y_train = np.array([np.array(item['cat_bin']) for item in L])\n",
    "\n",
    "    h1 = build_model(\n",
    "        text_input_shape=train.shape[1:],\n",
    "        output_shape=LB.classes_.shape[0],\n",
    "        **config[rep + '_kwargs'])\n",
    "    print(h1.summary(), flush=True)\n",
    "\n",
    "    h1_train_input_dict = dict(\n",
    "        name=rep,\n",
    "        model=h1,\n",
    "        X_text_train=train,\n",
    "        y_train=y_train,\n",
    "        class_weight=None,\n",
    "        batch_size=config['normal_batch_size'],\n",
    "        epochs=config['normal_' + rep + '_epochs'],\n",
    "        validation_split=config['normal_val_split'])\n",
    "\n",
    "    h1 = train_nn(**h1_train_input_dict)\n",
    "\n",
    "    test_input_dict = dict(\n",
    "        model=h1,\n",
    "        X_text_test=T_test,\n",
    "        batch_size=config['normal_batch_size'])\n",
    "    h1_y_pred = test_nn(**test_input_dict)\n",
    "    del T_test\n",
    "    gc.collect()\n",
    "\n",
    "    # test the performance of h1 on test set\n",
    "    print('=' * 50 + 'Predicting on Test Set....' + '=' * 50, flush=True)\n",
    "\n",
    "    h1_y_pred = np.array([[1 if j >= max(y) else 0 for j in y] for y in h1_y_pred])\n",
    "    h1_y_pred = LB.inverse_transform(h1_y_pred)\n",
    "\n",
    "    y_true = np.array([item['cat_bin'] for item in T])\n",
    "    y_true = LB.inverse_transform(y_true)\n",
    "\n",
    "    print(accuracy_score(y_true, h1_y_pred), flush=True)\n",
    "\n",
    "    print(classification_report(y_true, h1_y_pred), flush=True)\n",
    "#end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rfc(rep):\n",
    "    pprint('='*20 + rep + 'rfc' + '='*20)\n",
    "    global LE, L, config\n",
    "    train = np.array([np.array(item[rep]).flatten() for item in L])\n",
    "    y_train = np.array([np.array(item['cat_en']) for item in L])\n",
    "\n",
    "    rfc_param = dict(\n",
    "        n_jobs=8,\n",
    "        criterion='entropy',\n",
    "        max_depth=40,\n",
    "        n_estimators=100,\n",
    "        max_features='auto',\n",
    "        random_state=config['seed'],\n",
    "        min_impurity_decrease=0.001,\n",
    "        )\n",
    "\n",
    "    h1 = RandomForestClassifier(**rfc_param)\n",
    "    h1.fit(train, y_train)\n",
    "\n",
    "    # define the third combined classifier from h1 and h2,\n",
    "    # and test the performance of h1 and h2 on test set\n",
    "    print('=' * 50 + 'Predicting on Test Set....' + '=' * 50)\n",
    "    T_test = np.array([np.array(item[rep]).flatten() for item in T])\n",
    "    h1_y_pred = h1.predict_proba(T_test)\n",
    "    del T_test\n",
    "    gc.collect()\n",
    "\n",
    "    h1_y_pred = np.array([y.argmax() for y in h1_y_pred])\n",
    "    h1_y_pred = LE.inverse_transform(h1_y_pred)\n",
    "\n",
    "    y_true = np.array([item['cat_en'] for item in T])\n",
    "    y_true = LE.inverse_transform(y_true)\n",
    "\n",
    "    print(accuracy_score(y_true, h1_y_pred), flush=True)\n",
    "\n",
    "    print(classification_report(y_true, h1_y_pred), flush=True)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(rep):\n",
    "    pprint('='*20 + rep + 'xgb' + '='*20)\n",
    "    global LE, L, config\n",
    "    params_xgb = {\n",
    "        'eta': 0.01,\n",
    "        'max_depth': 15,\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree': 0.75,\n",
    "        'min_child_weight': 3,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': LE.classes_.shape[0],\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'seed': config['seed'],\n",
    "        'silent': 1,\n",
    "    }\n",
    "\n",
    "    train = np.array([np.array(item[rep]).flatten() for item in L])\n",
    "    y_train = np.array([np.array(item['cat_en']) for item in L])\n",
    "\n",
    "    train = xgboost.DMatrix(train, label=y_train)\n",
    "    h1 = xgboost.train(params_xgb, train, 30)\n",
    "\n",
    "    # define the third combined classifier from h1 and h2,\n",
    "    # and test the performance of h1 and h2 on test set\n",
    "    print('=' * 50 + 'Predicting on Test Set....' + '=' * 50)\n",
    "    T_test = np.array([np.array(item[rep]).flatten() for item in T])\n",
    "    T_test = xgboost.DMatrix(T_test)\n",
    "    h1_y_pred = h1.predict(T_test)\n",
    "    del T_test\n",
    "    gc.collect()\n",
    "\n",
    "    h1_y_pred = np.array([y.argmax() for y in h1_y_pred])\n",
    "    h1_y_pred = LE.inverse_transform(h1_y_pred)\n",
    "\n",
    "    y_true = np.array([item['cat_en'] for item in T])\n",
    "    y_true = LE.inverse_transform(y_true)\n",
    "\n",
    "    print(accuracy_score(y_true, h1_y_pred), flush=True)\n",
    "\n",
    "    print(classification_report(y_true, h1_y_pred), flush=True)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv(rep):\n",
    "    print('='*20 + rep + 'conv' + '='*20, flush=True)\n",
    "    global LB, L, T, TEXT_EMBEDDING_MATRIX, config\n",
    "    T_test = np.array([np.asarray(item[rep]) for item in T])\n",
    "\n",
    "    train = np.array([np.asarray(item[rep]) for item in L])\n",
    "\n",
    "    y_train = np.array([np.array(item['cat_bin']) for item in L])\n",
    "\n",
    "    h1 = build_conv_model(\n",
    "        text_input_shape=train.shape[1:],\n",
    "        output_shape=LB.classes_.shape[0],\n",
    "        **config[rep + '_kwargs'])\n",
    "    print(h1.summary(), flush=True)\n",
    "\n",
    "    h1_train_input_dict = dict(\n",
    "        name=rep,\n",
    "        model=h1,\n",
    "        X_text_train=train,\n",
    "        y_train=y_train,\n",
    "        class_weight=None,\n",
    "        batch_size=config['normal_batch_size'],\n",
    "        epochs=config['normal_' + rep + '_epochs'],\n",
    "        validation_split=config['normal_val_split'])\n",
    "\n",
    "    h1 = train_nn(**h1_train_input_dict)\n",
    "\n",
    "    test_input_dict = dict(\n",
    "        model=h1,\n",
    "        X_text_test=T_test,\n",
    "        batch_size=config['normal_batch_size'])\n",
    "    h1_y_pred = test_nn(**test_input_dict)\n",
    "    del T_test\n",
    "    gc.collect()\n",
    "\n",
    "    # test the performance of h1 on test set\n",
    "    print('=' * 50 + 'Predicting on Test Set....' + '=' * 50)\n",
    "\n",
    "    h1_y_pred = np.array([[1 if j >= max(y) else 0 for j in y] for y in h1_y_pred])\n",
    "    h1_y_pred = LB.inverse_transform(h1_y_pred)\n",
    "\n",
    "    y_true = np.array([item['cat_bin'] for item in T])\n",
    "    y_true = LB.inverse_transform(y_true)\n",
    "\n",
    "    print(accuracy_score(y_true, h1_y_pred), flush=True)\n",
    "\n",
    "    print(classification_report(y_true, h1_y_pred), flush=True)\n",
    "#end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support function for training nn-related algorithms\n",
    "def train_nn(\n",
    "    name,\n",
    "    model,\n",
    "    X_text_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=32,\n",
    "    validation_split=0.1,\n",
    "    **kwargs):\n",
    "    # define early stopping callback\n",
    "    callbacks_list = []\n",
    "    early_stopping = dict(monitor='val_loss',\n",
    "                            patience=3,\n",
    "                            min_delta=0.001, \n",
    "                            verbose=0,\n",
    "                            restore_best_weights=True)\n",
    "    model_checkpoint = dict(filepath='../models/20news/' + name + '_{val_loss:.5f}_{epoch:04d}.weights.h5',\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=True,\n",
    "                            mode='auto',\n",
    "                            period=1,\n",
    "                            verbose=0)\n",
    "\n",
    "    earlystop = EarlyStopping(**early_stopping)\n",
    "    callbacks_list.append(earlystop)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(**model_checkpoint)\n",
    "    callbacks_list.append(checkpoint)\n",
    "\n",
    "    x_dict = dict(text_input=X_text_train)\n",
    "    y_dict = dict(output=y_train)\n",
    "    model.fit(x_dict, y_dict,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks_list,\n",
    "        validation_split=validation_split,\n",
    "        verbose=0)\n",
    "    return model\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(\n",
    "    model,\n",
    "    X_text_test,\n",
    "    batch_size=128,\n",
    "    **kwargs):\n",
    "\n",
    "    x_dict = dict(text_input=X_text_test)\n",
    "    return model.predict(x_dict, batch_size=batch_size)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================doc2vecsvm====================\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.4318906001062135\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.26      0.32      0.29       319\n",
      "           comp.graphics       0.33      0.40      0.36       389\n",
      " comp.os.ms-windows.misc       0.30      0.31      0.30       394\n",
      "comp.sys.ibm.pc.hardware       0.34      0.36      0.35       392\n",
      "   comp.sys.mac.hardware       0.29      0.25      0.26       385\n",
      "          comp.windows.x       0.44      0.42      0.43       395\n",
      "            misc.forsale       0.55      0.57      0.56       390\n",
      "               rec.autos       0.53      0.47      0.50       396\n",
      "         rec.motorcycles       0.53      0.54      0.53       398\n",
      "      rec.sport.baseball       0.39      0.62      0.48       397\n",
      "        rec.sport.hockey       0.62      0.64      0.63       399\n",
      "               sci.crypt       0.71      0.51      0.59       396\n",
      "         sci.electronics       0.34      0.30      0.32       393\n",
      "                 sci.med       0.66      0.59      0.62       396\n",
      "               sci.space       0.53      0.53      0.53       394\n",
      "  soc.religion.christian       0.54      0.46      0.50       398\n",
      "      talk.politics.guns       0.37      0.37      0.37       364\n",
      "   talk.politics.mideast       0.40      0.39      0.39       376\n",
      "      talk.politics.misc       0.33      0.28      0.30       310\n",
      "      talk.religion.misc       0.16      0.12      0.14       251\n",
      "\n",
      "                accuracy                           0.43      7532\n",
      "               macro avg       0.43      0.42      0.42      7532\n",
      "            weighted avg       0.44      0.43      0.43      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm('doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================doc2vecmlp====================\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_input (InputLayer)      [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               154112    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 164,372\n",
      "Trainable params: 164,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.5047796070100903\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.23      0.53      0.32       319\n",
      "           comp.graphics       0.39      0.45      0.42       389\n",
      " comp.os.ms-windows.misc       0.42      0.29      0.35       394\n",
      "comp.sys.ibm.pc.hardware       0.45      0.35      0.39       392\n",
      "   comp.sys.mac.hardware       0.34      0.26      0.30       385\n",
      "          comp.windows.x       0.53      0.56      0.54       395\n",
      "            misc.forsale       0.58      0.69      0.63       390\n",
      "               rec.autos       0.61      0.63      0.62       396\n",
      "         rec.motorcycles       0.77      0.53      0.63       398\n",
      "      rec.sport.baseball       0.43      0.70      0.53       397\n",
      "        rec.sport.hockey       0.82      0.59      0.69       399\n",
      "               sci.crypt       0.76      0.62      0.68       396\n",
      "         sci.electronics       0.49      0.39      0.43       393\n",
      "                 sci.med       0.54      0.76      0.63       396\n",
      "               sci.space       0.58      0.64      0.61       394\n",
      "  soc.religion.christian       0.58      0.60      0.59       398\n",
      "      talk.politics.guns       0.53      0.41      0.46       364\n",
      "   talk.politics.mideast       0.50      0.56      0.53       376\n",
      "      talk.politics.misc       0.47      0.21      0.29       310\n",
      "      talk.religion.misc       0.32      0.08      0.13       251\n",
      "\n",
      "                accuracy                           0.50      7532\n",
      "               macro avg       0.52      0.49      0.49      7532\n",
      "            weighted avg       0.52      0.50      0.50      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_mlp('doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================doc2vecrfc===================='\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.34572490706319703\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.17      0.19      0.18       319\n",
      "           comp.graphics       0.22      0.23      0.22       389\n",
      " comp.os.ms-windows.misc       0.21      0.30      0.25       394\n",
      "comp.sys.ibm.pc.hardware       0.26      0.37      0.30       392\n",
      "   comp.sys.mac.hardware       0.20      0.13      0.16       385\n",
      "          comp.windows.x       0.34      0.35      0.35       395\n",
      "            misc.forsale       0.43      0.53      0.47       390\n",
      "               rec.autos       0.38      0.45      0.41       396\n",
      "         rec.motorcycles       0.30      0.35      0.32       398\n",
      "      rec.sport.baseball       0.43      0.45      0.44       397\n",
      "        rec.sport.hockey       0.41      0.58      0.48       399\n",
      "               sci.crypt       0.61      0.40      0.49       396\n",
      "         sci.electronics       0.31      0.24      0.27       393\n",
      "                 sci.med       0.56      0.57      0.56       396\n",
      "               sci.space       0.49      0.30      0.37       394\n",
      "  soc.religion.christian       0.40      0.54      0.46       398\n",
      "      talk.politics.guns       0.32      0.24      0.28       364\n",
      "   talk.politics.mideast       0.33      0.36      0.34       376\n",
      "      talk.politics.misc       0.24      0.10      0.14       310\n",
      "      talk.religion.misc       0.17      0.03      0.05       251\n",
      "\n",
      "                accuracy                           0.35      7532\n",
      "               macro avg       0.34      0.33      0.33      7532\n",
      "            weighted avg       0.35      0.35      0.34      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_rfc('doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================doc2vecxgb===================='\n",
      "[21:53:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.3056293149229952\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.24      0.19      0.21       319\n",
      "           comp.graphics       0.22      0.26      0.24       389\n",
      " comp.os.ms-windows.misc       0.22      0.25      0.24       394\n",
      "comp.sys.ibm.pc.hardware       0.32      0.25      0.28       392\n",
      "   comp.sys.mac.hardware       0.24      0.18      0.21       385\n",
      "          comp.windows.x       0.28      0.21      0.24       395\n",
      "            misc.forsale       0.38      0.48      0.42       390\n",
      "               rec.autos       0.33      0.37      0.35       396\n",
      "         rec.motorcycles       0.24      0.28      0.25       398\n",
      "      rec.sport.baseball       0.36      0.45      0.40       397\n",
      "        rec.sport.hockey       0.38      0.45      0.41       399\n",
      "               sci.crypt       0.41      0.37      0.39       396\n",
      "         sci.electronics       0.32      0.28      0.30       393\n",
      "                 sci.med       0.38      0.54      0.45       396\n",
      "               sci.space       0.29      0.28      0.28       394\n",
      "  soc.religion.christian       0.38      0.44      0.41       398\n",
      "      talk.politics.guns       0.27      0.23      0.25       364\n",
      "   talk.politics.mideast       0.25      0.27      0.26       376\n",
      "      talk.politics.misc       0.15      0.09      0.12       310\n",
      "      talk.religion.misc       0.15      0.05      0.08       251\n",
      "\n",
      "                accuracy                           0.31      7532\n",
      "               macro avg       0.29      0.30      0.29      7532\n",
      "            weighted avg       0.30      0.31      0.30      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_xgb('doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================tfidfsvm====================\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.6578597981943707\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.55      0.46      0.50       319\n",
      "           comp.graphics       0.53      0.51      0.52       389\n",
      " comp.os.ms-windows.misc       0.59      0.62      0.61       394\n",
      "comp.sys.ibm.pc.hardware       0.52      0.48      0.50       392\n",
      "   comp.sys.mac.hardware       0.68      0.65      0.66       385\n",
      "          comp.windows.x       0.66      0.67      0.67       395\n",
      "            misc.forsale       0.68      0.83      0.75       390\n",
      "               rec.autos       0.67      0.70      0.68       396\n",
      "         rec.motorcycles       0.69      0.66      0.67       398\n",
      "      rec.sport.baseball       0.74      0.77      0.75       397\n",
      "        rec.sport.hockey       0.81      0.85      0.83       399\n",
      "               sci.crypt       0.83      0.82      0.83       396\n",
      "         sci.electronics       0.50      0.47      0.48       393\n",
      "                 sci.med       0.72      0.64      0.68       396\n",
      "               sci.space       0.73      0.80      0.76       394\n",
      "  soc.religion.christian       0.55      0.79      0.65       398\n",
      "      talk.politics.guns       0.62      0.76      0.68       364\n",
      "   talk.politics.mideast       0.84      0.76      0.80       376\n",
      "      talk.politics.misc       0.63      0.43      0.51       310\n",
      "      talk.religion.misc       0.49      0.27      0.35       251\n",
      "\n",
      "                accuracy                           0.66      7532\n",
      "               macro avg       0.65      0.65      0.64      7532\n",
      "            weighted avg       0.66      0.66      0.65      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================tfidfmlp====================\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_input (InputLayer)      [(None, 10000)]           0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 5,130,772\n",
      "Trainable params: 5,130,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.6517525225703664\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.66      0.42      0.51       319\n",
      "           comp.graphics       0.61      0.48      0.54       389\n",
      " comp.os.ms-windows.misc       0.44      0.72      0.55       394\n",
      "comp.sys.ibm.pc.hardware       0.53      0.49      0.51       392\n",
      "   comp.sys.mac.hardware       0.50      0.70      0.58       385\n",
      "          comp.windows.x       0.78      0.63      0.70       395\n",
      "            misc.forsale       0.61      0.84      0.71       390\n",
      "               rec.autos       0.74      0.63      0.68       396\n",
      "         rec.motorcycles       0.70      0.70      0.70       398\n",
      "      rec.sport.baseball       0.66      0.85      0.74       397\n",
      "        rec.sport.hockey       0.91      0.79      0.85       399\n",
      "               sci.crypt       0.94      0.73      0.82       396\n",
      "         sci.electronics       0.57      0.42      0.49       393\n",
      "                 sci.med       0.74      0.63      0.68       396\n",
      "               sci.space       0.81      0.75      0.78       394\n",
      "  soc.religion.christian       0.67      0.69      0.68       398\n",
      "      talk.politics.guns       0.70      0.66      0.68       364\n",
      "   talk.politics.mideast       0.88      0.76      0.82       376\n",
      "      talk.politics.misc       0.65      0.48      0.55       310\n",
      "      talk.religion.misc       0.31      0.52      0.39       251\n",
      "\n",
      "                accuracy                           0.65      7532\n",
      "               macro avg       0.67      0.65      0.65      7532\n",
      "            weighted avg       0.68      0.65      0.66      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_mlp('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================tfidfrfc===================='\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.44848645778013807\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.45      0.26      0.33       319\n",
      "           comp.graphics       0.31      0.24      0.27       389\n",
      " comp.os.ms-windows.misc       0.41      0.61      0.49       394\n",
      "comp.sys.ibm.pc.hardware       0.31      0.33      0.32       392\n",
      "   comp.sys.mac.hardware       0.39      0.32      0.35       385\n",
      "          comp.windows.x       0.37      0.36      0.37       395\n",
      "            misc.forsale       0.58      0.77      0.66       390\n",
      "               rec.autos       0.38      0.48      0.43       396\n",
      "         rec.motorcycles       0.23      0.49      0.31       398\n",
      "      rec.sport.baseball       0.49      0.47      0.48       397\n",
      "        rec.sport.hockey       0.64      0.65      0.64       399\n",
      "               sci.crypt       0.69      0.68      0.69       396\n",
      "         sci.electronics       0.28      0.18      0.21       393\n",
      "                 sci.med       0.28      0.19      0.23       396\n",
      "               sci.space       0.64      0.51      0.57       394\n",
      "  soc.religion.christian       0.47      0.71      0.57       398\n",
      "      talk.politics.guns       0.56      0.63      0.59       364\n",
      "   talk.politics.mideast       0.76      0.52      0.62       376\n",
      "      talk.politics.misc       0.57      0.27      0.37       310\n",
      "      talk.religion.misc       0.57      0.11      0.19       251\n",
      "\n",
      "                accuracy                           0.45      7532\n",
      "               macro avg       0.47      0.44      0.43      7532\n",
      "            weighted avg       0.47      0.45      0.44      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_rfc('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================tfidfxgb===================='\n",
      "[22:09:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.2661975570897504\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.13      0.11      0.12       319\n",
      "           comp.graphics       0.15      0.16      0.16       389\n",
      " comp.os.ms-windows.misc       0.52      0.53      0.52       394\n",
      "comp.sys.ibm.pc.hardware       0.21      0.22      0.22       392\n",
      "   comp.sys.mac.hardware       0.09      0.19      0.12       385\n",
      "          comp.windows.x       0.21      0.21      0.21       395\n",
      "            misc.forsale       0.64      0.63      0.63       390\n",
      "               rec.autos       0.32      0.34      0.33       396\n",
      "         rec.motorcycles       0.18      0.10      0.13       398\n",
      "      rec.sport.baseball       0.18      0.25      0.21       397\n",
      "        rec.sport.hockey       0.34      0.34      0.34       399\n",
      "               sci.crypt       0.69      0.47      0.56       396\n",
      "         sci.electronics       0.15      0.14      0.14       393\n",
      "                 sci.med       0.05      0.06      0.05       396\n",
      "               sci.space       0.48      0.38      0.42       394\n",
      "  soc.religion.christian       0.34      0.46      0.39       398\n",
      "      talk.politics.guns       0.25      0.31      0.27       364\n",
      "   talk.politics.mideast       0.26      0.11      0.15       376\n",
      "      talk.politics.misc       0.14      0.11      0.12       310\n",
      "      talk.religion.misc       0.24      0.07      0.11       251\n",
      "\n",
      "                accuracy                           0.27      7532\n",
      "               macro avg       0.28      0.26      0.26      7532\n",
      "            weighted avg       0.28      0.27      0.27      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_xgb('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================usesvm====================\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.676048858204992\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.51      0.45      0.47       319\n",
      "           comp.graphics       0.52      0.52      0.52       389\n",
      " comp.os.ms-windows.misc       0.57      0.54      0.56       394\n",
      "comp.sys.ibm.pc.hardware       0.48      0.46      0.47       392\n",
      "   comp.sys.mac.hardware       0.52      0.52      0.52       385\n",
      "          comp.windows.x       0.61      0.64      0.62       395\n",
      "            misc.forsale       0.73      0.86      0.79       390\n",
      "               rec.autos       0.80      0.82      0.81       396\n",
      "         rec.motorcycles       0.77      0.75      0.76       398\n",
      "      rec.sport.baseball       0.89      0.87      0.88       397\n",
      "        rec.sport.hockey       0.88      0.91      0.90       399\n",
      "               sci.crypt       0.71      0.69      0.70       396\n",
      "         sci.electronics       0.61      0.50      0.55       393\n",
      "                 sci.med       0.80      0.85      0.82       396\n",
      "               sci.space       0.79      0.79      0.79       394\n",
      "  soc.religion.christian       0.66      0.80      0.72       398\n",
      "      talk.politics.guns       0.60      0.74      0.67       364\n",
      "   talk.politics.mideast       0.82      0.80      0.81       376\n",
      "      talk.politics.misc       0.55      0.50      0.52       310\n",
      "      talk.religion.misc       0.44      0.25      0.32       251\n",
      "\n",
      "                accuracy                           0.68      7532\n",
      "               macro avg       0.66      0.66      0.66      7532\n",
      "            weighted avg       0.67      0.68      0.67      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================usemlp====================\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_input (InputLayer)      [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 272,916\n",
      "Trainable params: 272,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.6881306425916092\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.45      0.59      0.51       319\n",
      "           comp.graphics       0.56      0.57      0.56       389\n",
      " comp.os.ms-windows.misc       0.57      0.58      0.58       394\n",
      "comp.sys.ibm.pc.hardware       0.51      0.44      0.48       392\n",
      "   comp.sys.mac.hardware       0.49      0.56      0.52       385\n",
      "          comp.windows.x       0.65      0.62      0.64       395\n",
      "            misc.forsale       0.75      0.85      0.80       390\n",
      "               rec.autos       0.79      0.85      0.82       396\n",
      "         rec.motorcycles       0.73      0.79      0.76       398\n",
      "      rec.sport.baseball       0.89      0.86      0.88       397\n",
      "        rec.sport.hockey       0.93      0.90      0.92       399\n",
      "               sci.crypt       0.74      0.73      0.74       396\n",
      "         sci.electronics       0.64      0.51      0.57       393\n",
      "                 sci.med       0.76      0.86      0.81       396\n",
      "               sci.space       0.83      0.79      0.81       394\n",
      "  soc.religion.christian       0.74      0.76      0.75       398\n",
      "      talk.politics.guns       0.61      0.71      0.65       364\n",
      "   talk.politics.mideast       0.86      0.79      0.82       376\n",
      "      talk.politics.misc       0.61      0.49      0.54       310\n",
      "      talk.religion.misc       0.52      0.26      0.35       251\n",
      "\n",
      "                accuracy                           0.69      7532\n",
      "               macro avg       0.68      0.68      0.68      7532\n",
      "            weighted avg       0.69      0.69      0.68      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_mlp('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================userfc===================='\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.641927774827403\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.52      0.36      0.43       319\n",
      "           comp.graphics       0.50      0.43      0.46       389\n",
      " comp.os.ms-windows.misc       0.52      0.63      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.48      0.48      0.48       392\n",
      "   comp.sys.mac.hardware       0.46      0.38      0.42       385\n",
      "          comp.windows.x       0.57      0.61      0.59       395\n",
      "            misc.forsale       0.69      0.66      0.67       390\n",
      "               rec.autos       0.74      0.85      0.79       396\n",
      "         rec.motorcycles       0.67      0.71      0.69       398\n",
      "      rec.sport.baseball       0.87      0.86      0.86       397\n",
      "        rec.sport.hockey       0.89      0.88      0.88       399\n",
      "               sci.crypt       0.71      0.67      0.69       396\n",
      "         sci.electronics       0.58      0.50      0.54       393\n",
      "                 sci.med       0.72      0.85      0.78       396\n",
      "               sci.space       0.76      0.75      0.75       394\n",
      "  soc.religion.christian       0.57      0.85      0.68       398\n",
      "      talk.politics.guns       0.56      0.73      0.63       364\n",
      "   talk.politics.mideast       0.84      0.80      0.82       376\n",
      "      talk.politics.misc       0.50      0.39      0.44       310\n",
      "      talk.religion.misc       0.48      0.16      0.24       251\n",
      "\n",
      "                accuracy                           0.64      7532\n",
      "               macro avg       0.63      0.63      0.62      7532\n",
      "            weighted avg       0.64      0.64      0.63      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_rfc('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================usexgb===================='\n",
      "[23:06:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.5823154540626659\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.45      0.41      0.43       319\n",
      "           comp.graphics       0.44      0.39      0.41       389\n",
      " comp.os.ms-windows.misc       0.54      0.47      0.50       394\n",
      "comp.sys.ibm.pc.hardware       0.42      0.44      0.43       392\n",
      "   comp.sys.mac.hardware       0.39      0.29      0.34       385\n",
      "          comp.windows.x       0.52      0.61      0.56       395\n",
      "            misc.forsale       0.50      0.70      0.58       390\n",
      "               rec.autos       0.76      0.74      0.75       396\n",
      "         rec.motorcycles       0.63      0.62      0.62       398\n",
      "      rec.sport.baseball       0.82      0.80      0.81       397\n",
      "        rec.sport.hockey       0.78      0.85      0.81       399\n",
      "               sci.crypt       0.60      0.56      0.58       396\n",
      "         sci.electronics       0.49      0.42      0.45       393\n",
      "                 sci.med       0.77      0.78      0.77       396\n",
      "               sci.space       0.68      0.71      0.70       394\n",
      "  soc.religion.christian       0.55      0.73      0.63       398\n",
      "      talk.politics.guns       0.57      0.56      0.57       364\n",
      "   talk.politics.mideast       0.77      0.76      0.76       376\n",
      "      talk.politics.misc       0.35      0.39      0.37       310\n",
      "      talk.religion.misc       0.37      0.18      0.24       251\n",
      "\n",
      "                accuracy                           0.58      7532\n",
      "               macro avg       0.57      0.57      0.57      7532\n",
      "            weighted avg       0.58      0.58      0.58      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_xgb('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================pooledbertsvm====================\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "(768,)\n",
      "(16, 768)\n",
      "(300,)\n",
      "0.40626659585767394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.43      0.42      0.43       319\n",
      "           comp.graphics       0.25      0.24      0.24       389\n",
      " comp.os.ms-windows.misc       0.27      0.23      0.25       394\n",
      "comp.sys.ibm.pc.hardware       0.23      0.24      0.23       392\n",
      "   comp.sys.mac.hardware       0.25      0.18      0.21       385\n",
      "          comp.windows.x       0.34      0.39      0.36       395\n",
      "            misc.forsale       0.51      0.67      0.58       390\n",
      "               rec.autos       0.47      0.52      0.50       396\n",
      "         rec.motorcycles       0.39      0.32      0.35       398\n",
      "      rec.sport.baseball       0.45      0.43      0.44       397\n",
      "        rec.sport.hockey       0.53      0.54      0.54       399\n",
      "               sci.crypt       0.47      0.41      0.44       396\n",
      "         sci.electronics       0.25      0.21      0.23       393\n",
      "                 sci.med       0.51      0.60      0.55       396\n",
      "               sci.space       0.53      0.56      0.54       394\n",
      "  soc.religion.christian       0.49      0.51      0.50       398\n",
      "      talk.politics.guns       0.40      0.46      0.43       364\n",
      "   talk.politics.mideast       0.59      0.58      0.58       376\n",
      "      talk.politics.misc       0.30      0.30      0.30       310\n",
      "      talk.religion.misc       0.26      0.24      0.25       251\n",
      "\n",
      "                accuracy                           0.41      7532\n",
      "               macro avg       0.40      0.40      0.40      7532\n",
      "            weighted avg       0.40      0.41      0.40      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm('pooledbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================pooledbertmlp====================\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_input (InputLayer)      [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               393728    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 403,988\n",
      "Trainable params: 403,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.2622145512480085\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.21      0.29      0.25       319\n",
      "           comp.graphics       0.00      0.00      0.00       389\n",
      " comp.os.ms-windows.misc       0.13      0.14      0.14       394\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       392\n",
      "   comp.sys.mac.hardware       0.26      0.12      0.16       385\n",
      "          comp.windows.x       0.19      0.64      0.29       395\n",
      "            misc.forsale       0.43      0.58      0.49       390\n",
      "               rec.autos       0.17      0.36      0.24       396\n",
      "         rec.motorcycles       0.29      0.07      0.11       398\n",
      "      rec.sport.baseball       0.44      0.10      0.17       397\n",
      "        rec.sport.hockey       0.25      0.75      0.37       399\n",
      "               sci.crypt       0.37      0.14      0.20       396\n",
      "         sci.electronics       0.19      0.06      0.10       393\n",
      "                 sci.med       0.63      0.25      0.36       396\n",
      "               sci.space       0.27      0.55      0.36       394\n",
      "  soc.religion.christian       0.37      0.46      0.41       398\n",
      "      talk.politics.guns       0.27      0.08      0.12       364\n",
      "   talk.politics.mideast       0.48      0.28      0.35       376\n",
      "      talk.politics.misc       0.32      0.08      0.12       310\n",
      "      talk.religion.misc       0.20      0.20      0.20       251\n",
      "\n",
      "                accuracy                           0.26      7532\n",
      "               macro avg       0.27      0.26      0.22      7532\n",
      "            weighted avg       0.27      0.26      0.22      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"): # to offset Blas GEMM launch failed\n",
    "    train_mlp('pooledbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================pooledbertrfc===================='\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.20300053106744556\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.26      0.22      0.24       319\n",
      "           comp.graphics       0.10      0.13      0.11       389\n",
      " comp.os.ms-windows.misc       0.13      0.18      0.15       394\n",
      "comp.sys.ibm.pc.hardware       0.14      0.11      0.12       392\n",
      "   comp.sys.mac.hardware       0.11      0.09      0.10       385\n",
      "          comp.windows.x       0.22      0.28      0.25       395\n",
      "            misc.forsale       0.33      0.36      0.34       390\n",
      "               rec.autos       0.18      0.15      0.16       396\n",
      "         rec.motorcycles       0.11      0.11      0.11       398\n",
      "      rec.sport.baseball       0.23      0.22      0.23       397\n",
      "        rec.sport.hockey       0.22      0.29      0.25       399\n",
      "               sci.crypt       0.19      0.20      0.20       396\n",
      "         sci.electronics       0.12      0.12      0.12       393\n",
      "                 sci.med       0.28      0.24      0.26       396\n",
      "               sci.space       0.25      0.19      0.22       394\n",
      "  soc.religion.christian       0.26      0.31      0.28       398\n",
      "      talk.politics.guns       0.24      0.19      0.21       364\n",
      "   talk.politics.mideast       0.30      0.33      0.31       376\n",
      "      talk.politics.misc       0.20      0.15      0.17       310\n",
      "      talk.religion.misc       0.26      0.16      0.20       251\n",
      "\n",
      "                accuracy                           0.20      7532\n",
      "               macro avg       0.21      0.20      0.20      7532\n",
      "            weighted avg       0.20      0.20      0.20      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_rfc('pooledbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'====================pooledbertxgb===================='\n",
      "[16:24:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.2134891131173659\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.24      0.19      0.21       319\n",
      "           comp.graphics       0.13      0.09      0.11       389\n",
      " comp.os.ms-windows.misc       0.18      0.17      0.17       394\n",
      "comp.sys.ibm.pc.hardware       0.16      0.09      0.11       392\n",
      "   comp.sys.mac.hardware       0.10      0.11      0.10       385\n",
      "          comp.windows.x       0.22      0.28      0.24       395\n",
      "            misc.forsale       0.35      0.38      0.36       390\n",
      "               rec.autos       0.20      0.19      0.20       396\n",
      "         rec.motorcycles       0.19      0.21      0.20       398\n",
      "      rec.sport.baseball       0.20      0.25      0.22       397\n",
      "        rec.sport.hockey       0.27      0.33      0.30       399\n",
      "               sci.crypt       0.19      0.20      0.19       396\n",
      "         sci.electronics       0.09      0.07      0.08       393\n",
      "                 sci.med       0.25      0.23      0.24       396\n",
      "               sci.space       0.18      0.21      0.20       394\n",
      "  soc.religion.christian       0.27      0.42      0.33       398\n",
      "      talk.politics.guns       0.22      0.18      0.20       364\n",
      "   talk.politics.mideast       0.38      0.35      0.37       376\n",
      "      talk.politics.misc       0.15      0.15      0.15       310\n",
      "      talk.religion.misc       0.18      0.10      0.12       251\n",
      "\n",
      "                accuracy                           0.21      7532\n",
      "               macro avg       0.21      0.21      0.21      7532\n",
      "            weighted avg       0.21      0.21      0.21      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_xgb('pooledbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================seqbertconv====================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_input (InputLayer)      [(None, 16, 768)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 14, 256)           590080    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 595,220\n",
      "Trainable params: 595,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "==================================================Predicting on Test Set....==================================================\n",
      "0.5345193839617631\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.35      0.47       319\n",
      "           comp.graphics       0.46      0.22      0.30       389\n",
      " comp.os.ms-windows.misc       0.49      0.36      0.41       394\n",
      "comp.sys.ibm.pc.hardware       0.35      0.44      0.39       392\n",
      "   comp.sys.mac.hardware       0.41      0.28      0.33       385\n",
      "          comp.windows.x       0.42      0.54      0.47       395\n",
      "            misc.forsale       0.64      0.75      0.69       390\n",
      "               rec.autos       0.60      0.65      0.62       396\n",
      "         rec.motorcycles       0.49      0.47      0.48       398\n",
      "      rec.sport.baseball       0.59      0.53      0.56       397\n",
      "        rec.sport.hockey       0.65      0.63      0.64       399\n",
      "               sci.crypt       0.44      0.75      0.56       396\n",
      "         sci.electronics       0.32      0.40      0.36       393\n",
      "                 sci.med       0.70      0.71      0.70       396\n",
      "               sci.space       0.74      0.68      0.71       394\n",
      "  soc.religion.christian       0.52      0.75      0.61       398\n",
      "      talk.politics.guns       0.79      0.42      0.55       364\n",
      "   talk.politics.mideast       0.79      0.73      0.76       376\n",
      "      talk.politics.misc       0.41      0.49      0.45       310\n",
      "      talk.religion.misc       0.48      0.46      0.47       251\n",
      "\n",
      "                accuracy                           0.53      7532\n",
      "               macro avg       0.55      0.53      0.53      7532\n",
      "            weighted avg       0.55      0.53      0.53      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_conv('seqbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
