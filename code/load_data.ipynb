{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "from pprint import pprint\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.utils import shuffle\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "twentynews_dir = '../data/20news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path(df_path, rand=False, rand_seed=4079):\n",
    "    df = pd.read_csv(df_path)\n",
    "    if rand:\n",
    "        df = shuffle(df, random_state=rand_seed)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_clean(text):\n",
    "    text = clean(\n",
    "        text,\n",
    "        lower=False,\n",
    "        no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "        no_urls=True,                  # replace all URLs with a special token\n",
    "        no_emails=True,                # replace all email addresses with a special token\n",
    "        no_punct=True,                 # fully remove punctuation\n",
    "        )\n",
    "    return re.sub(r'[#$%^&*)(|/><\"\\\\}{]', ' ', text)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_path(train_df, train_path, test_df, test_path, compress=3):\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download 20news from online\n",
    "def save_twentynews(save=True, default_split=True, train_test_ratio=0.7, rand_seed=4079):\n",
    "    def _process_doc(doc):\n",
    "        lines = doc.split('\\n')\n",
    "        keep = list()\n",
    "\n",
    "        for i, l in enumerate(lines):\n",
    "            if l.startswith('Subject:'):\n",
    "                keep.append(l[9:])\n",
    "            if l.startswith('Lines:'):\n",
    "                break\n",
    "        # end for\n",
    "\n",
    "        keep += lines[i+1:]\n",
    "\n",
    "        return ' '.join(keep)\n",
    "    # end def\n",
    "\n",
    "    train_list = list()\n",
    "    test_list = list()\n",
    "\n",
    "    if default_split:\n",
    "        train_newsgroups = fetch_20newsgroups(subset='train', remove=('header', 'footers', 'quotes'))  # , remove=('headers', 'footers', 'quotes'))\n",
    "        test_newsgroups = fetch_20newsgroups(subset='test', remove=('header', 'footers', 'quotes'))  # , remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "        train_file_names = train_newsgroups.filenames\n",
    "        train_target_names = train_newsgroups.target_names\n",
    "        train_targets = train_newsgroups.target\n",
    "        train_docs = train_newsgroups.data\n",
    "\n",
    "        test_file_names = test_newsgroups.filenames\n",
    "        test_target_names = test_newsgroups.target_names\n",
    "        test_targets = test_newsgroups.target\n",
    "        test_docs = test_newsgroups.data\n",
    "\n",
    "        train_list += [dict(id=train_file_names[i].split('/')[-1], doc=_process_doc(_doc), cat=train_target_names[train_targets[i]]) for i, _doc in enumerate(train_docs)]\n",
    "        pprint(x for x in train_list if x['id'] == 'C:\\\\Users\\\\User\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\talk.politics.mideast\\\\75889')\n",
    "        test_list += [dict(id=test_file_names[i].split('/')[-1], doc=_process_doc(_doc), cat=test_target_names[test_targets[i]]) for i, _doc in enumerate(test_docs)]\n",
    "    else:\n",
    "        all_newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=rand_seed)\n",
    "        all_file_names = all_newsgroups.filenames\n",
    "        all_file_names = [fname.split('/')[-1] for fname in all_file_names]\n",
    "        all_target_names = all_newsgroups.target_names\n",
    "        all_targets = all_newsgroups.target\n",
    "        all_docs = all_newsgroups.data\n",
    "\n",
    "        idx = math.floor(train_test_ratio * len(all_docs))\n",
    "\n",
    "        train_file_names = all_file_names[:idx]\n",
    "        train_targets = all_targets[:idx]\n",
    "        train_docs = all_docs[:idx]\n",
    "\n",
    "        test_file_names = all_file_names[idx:]\n",
    "        test_targets = all_targets[idx:]\n",
    "        test_docs = all_docs[idx:]\n",
    "        del all_newsgroups, all_file_names, all_targets, all_docs\n",
    "\n",
    "        train_list += [dict(id=train_file_names[i], doc=_doc.replace('\\n', ' ').replace('\\t', ' '), cat=all_target_names[train_targets[i]]) for i, _doc in enumerate(train_docs)]\n",
    "        test_list += [dict(id=test_file_names[i], doc=_doc.replace('\\n', ' ').replace('\\t', ' '), cat=all_target_names[test_targets[i]]) for i, _doc in enumerate(test_docs)]\n",
    "    # end if\n",
    "\n",
    "    train_df = pd.DataFrame(train_list).sample(frac=1).reset_index(drop=True)\n",
    "    pprint(train_df.iloc[2324]['id'])\n",
    "    train_df['doc'] = train_df['doc'].apply(lambda x: cust_clean(x))\n",
    "    pprint(train_df.iloc[2324])\n",
    "    test_df = pd.DataFrame(test_list).sample(frac=1).reset_index(drop=True)\n",
    "    test_df['doc'] = test_df['doc'].apply(lambda x: cust_clean(x))\n",
    "\n",
    "    pprint(\"Number of train: {}\".format(train_df.shape[0]))\n",
    "    pprint(\"Number of test: {}\".format(test_df.shape[0]))\n",
    "    if save:\n",
    "        train_path = os.path.join(twentynews_dir, 'train.csv')\n",
    "        test_path = os.path.join(twentynews_dir, 'test.csv')\n",
    "        save_to_path(train_df, train_path, test_df, test_path)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object save_twentynews.<locals>.<genexpr> at 0x0000020FBD6C6350>\n",
      "'C:\\\\Users\\\\User\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\talk.politics.guns\\\\54719'\n",
      "id     C:\\Users\\User\\scikit_learn_data\\20news_home\\20...\n",
      "doc    Re NRA address Distribution world NNTPPostingH...\n",
      "cat                                   talk.politics.guns\n",
      "Name: 2324, dtype: object\n",
      "'Number of train: 11314'\n",
      "'Number of test: 7532'\n"
     ]
    }
   ],
   "source": [
    "save_twentynews(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From article   EMAIL   by  EMAIL  Tom A Baker My understanding is that the expected errors are basically known bugs in the warning system software things are checked that dont have the right values in yet because they arent set till after launch and suchlike Rather than fix the code and possibly introduce new bugs they just tell the crew ok if you see a warning no 213 before liftoff ignore it'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
